<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://rezkaaufar.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://rezkaaufar.github.io/" rel="alternate" type="text/html" /><updated>2022-11-12T10:49:41+07:00</updated><id>https://rezkaaufar.github.io/feed.xml</id><title type="html">blank</title><subtitle>Rezka's Personal Website and Blog
</subtitle><entry><title type="html">Target rate for class imbalance</title><link href="https://rezkaaufar.github.io/blog/2022/target-rate/" rel="alternate" type="text/html" title="Target rate for class imbalance" /><published>2022-05-25T00:00:00+07:00</published><updated>2022-05-25T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2022/target-rate</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2022/target-rate/">&lt;p&gt;Class imbalance is a common problem in machine learning, where the negative class greatly outnumbers the positive class (or vice versa). I recently watch a &lt;a href=&quot;https://www.youtube.com/watch?v=rHSpab1Wi9k&quot;&gt;talk from stripe&lt;/a&gt; where they share their techniques in addressing class imbalance in a credit card fraud detection system. I decided to create a summary here and try it out for myself on a &lt;a href=&quot;https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets&quot;&gt;credit card fraud public dataset&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;target-rate&quot;&gt;Target rate&lt;/h1&gt;
&lt;p&gt;The objective is to create a model which can predict whether a transaction is fraudulent. The model is a binary classifier which produces a score in the 0-1 range, where 0 indicates no fraud and 1 indicates fraud. Based on what they’ve found, training on imbalance data and validating the metrics on imbalance data produces worse result compared to training and validating on a more balanced data. Why?&lt;/p&gt;

&lt;p&gt;With a binary classifier model, we need to choose a threshold that satisfies some criteria on the validation data. This threshold is used to determine whether an instance is going to predicted as fraud or not. What they want to do in their case is that they want to maximize recall while capping FPR (false positive rate).
Say we have initially a training + validation data with less than 1% fraudulent label (the positive label). If we optimize only for recall and FPR, we can get a low FPR but extremely low precision. Why is this happening? FPR is low because the denominator of the negative label is extremely huge. The model can predict a lot of false positives and still get low FPR in this case. Then during the threshold picking phase on the validation set, we can just pick a relatively low threshold, which results in high recall but extremely low precision. Hence we need to do something on the class imbalance.&lt;/p&gt;

&lt;p&gt;However, if we train and validate on a balanced dataset, we are going to be faced with class imbalance again on the production. That is why we need to find a balance that works best in production.&lt;/p&gt;

&lt;p&gt;Their idea is to try to create a balanced training set that works well on the extremely imbalanced production data. Basically what we want to find is a percentage of fraud (x%) and the percentage of non-fraud training data instances (100-x%) that maximizes performances on the validation data which still contains the original proportion of the class imbalance. The percentage (x) is called the target rate. Then what we do is we can use grid/exhaustive search, trying out different values of x by keeping every fraudulent dataset and downsample the non-fraudulent dataset to create the dataset according to the target rate. After that, they evaluate the performance in validation set and also the performance in production.&lt;/p&gt;

&lt;h1 id=&quot;my-own-experiment&quot;&gt;My own experiment&lt;/h1&gt;

&lt;p&gt;To see how helpful is this target rate idea, I decided to try it out on a &lt;a href=&quot;https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets&quot;&gt;credit card fraud public dataset&lt;/a&gt;. The dataset is extremely imbalanced with only 0.0001 percent of fraud dataset. I try different target rate from 0.1 to 1 and train XGBoost model with the balanced training data. Then I evaluate the XGBoost model on the imbalanced validation set and below is the result I get:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/target-rate-result-800x427.png&quot; srcset=&quot;    /assets/resized/target-rate-result-480x256.png 480w,    /assets/resized/target-rate-result-800x427.png 800w,/assets/img/target-rate-result.png 1080w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: Precision, recall, and roc scores on different target rate.
&lt;/div&gt;

&lt;p&gt;We can see that the graph looks wiggly, and perhaps that the best tradeoff between the three metrics is between 0.3-0.4 target rate. Now I would say that this technique is helpful to some extent if we want to do better downsampling. However, I think that the result is prone to random samples and the random seed that we initialize. So I’m not entirely convinced that this is the best method to overcome extremely imbalanced dataset.&lt;/p&gt;

&lt;h1 id=&quot;closing&quot;&gt;Closing&lt;/h1&gt;

&lt;p&gt;Thanks for reading! If you think I am missing something please comment below. For those interested you can check my code &lt;a href=&quot;https://github.com/rezkaaufar/target-rate/blob/master/target-rate-imbalanced-dataset.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Class imbalance is a common problem in machine learning, where the negative class greatly outnumbers the positive class (or vice versa). I recently watch a talk from stripe where they share their techniques in addressing class imbalance in a credit card fraud detection system. I decided to create a summary here and try it out for myself on a credit card fraud public dataset.</summary></entry><entry><title type="html">Search fundamentals (part 1)</title><link href="https://rezkaaufar.github.io/blog/2022/search-fundamentals-pt1/" rel="alternate" type="text/html" title="Search fundamentals (part 1)" /><published>2022-04-29T00:00:00+07:00</published><updated>2022-04-29T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2022/search-fundamentals-pt1</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2022/search-fundamentals-pt1/">&lt;p&gt;Have you ever wondered how search engine works? How can they match a query with millions of documents super fast and return them in a personalized way for each users? There are a lot of engineering techniques that power a search engine.&lt;/p&gt;

&lt;p&gt;In this post, we are going to look at two components of a search engine. In a simplified view, search engine is composed of two main parts: retrieval and reranking.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-query-document-1400x459.png&quot; srcset=&quot;    /assets/resized/search-query-document-480x158.png 480w,    /assets/resized/search-query-document-800x263.png 800w,    /assets/resized/search-query-document-1400x459.png 1400w,/assets/img/search-query-document.png 1408w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: Query and document.
&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;retrieval&quot;&gt;Retrieval&lt;/h1&gt;
&lt;p&gt;In retrieval, we want to return a smaller pool of documents from the huge pools given a query. We essentially want to reduce the number of document candidates that can potentially be of interest according to a given query.&lt;/p&gt;

&lt;p&gt;There are many techniques to do retrieval, but the key point is retrieval needs to be fast. In Big-O notation, we want the retrieval to have a time complexity in \(\mathcal{O}(1)\) or at most in \(\mathcal{O}(\log N)\). Higher time complexity yields to slow and unpleasant experience for users.&lt;/p&gt;

&lt;h2 id=&quot;retrieval-with-inverted-index&quot;&gt;Retrieval with inverted index&lt;/h2&gt;

&lt;p&gt;For the sake of simplicity, let’s assume that the query and documents that we have are of string types. To do retrieval fast, we create an inverted index which stores every unique token (vocabulary) that can be found in the document pool and points to document subset containing this token.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-inverted-index-1400x631.png&quot; srcset=&quot;    /assets/resized/search-inverted-index-480x216.png 480w,    /assets/resized/search-inverted-index-800x361.png 800w,    /assets/resized/search-inverted-index-1400x631.png 1400w,/assets/img/search-inverted-index.png 1632w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 2: Inverted index.
&lt;/div&gt;

&lt;p&gt;So instead of doing a string match of each query term to the document term, we can directly access the index to return the list of documents of matched query in \(\mathcal{O}(1)\) time complexity.&lt;/p&gt;

&lt;p&gt;In popular search libraries such as elastic search, we can adjust further on preprocessing (e.g., tokenizing) and on how to define the match. For preprocessing, we can stem words to only include base word, tokenize word using different delimiters, and many more. For match definition, we can determine whether we want full match of all query term, partial match only, or any other heuristics. These heuristics give you some control on which criteria you want the documents to be returned.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-match-1400x689.png&quot; srcset=&quot;    /assets/resized/search-match-480x236.png 480w,    /assets/resized/search-match-800x394.png 800w,    /assets/resized/search-match-1400x689.png 1400w,/assets/img/search-match.png 1726w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 3: Inverted index match case.
&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;reranking&quot;&gt;Reranking&lt;/h1&gt;

&lt;p&gt;We need to assign a score to each of the retrieved documents so that we can get the rank from the most relevant items the least relevant items with respect to the query term. There are many ways to assign score to each retrieved documents, from the older approach like tf-idf and bm25 to the more neural network approach. In this post, we’ll take a look at tf-idf.&lt;/p&gt;

&lt;h2 id=&quot;tf-idf-scoring&quot;&gt;TF-IDF scoring&lt;/h2&gt;
&lt;p&gt;As the name suggest, there are two components in tf-idf: term frequency - inverse document frequency.&lt;/p&gt;

&lt;p&gt;Given a word \(t\) and document \(d\), term frequency \(f_{t,d}\) is simply the number of times each word \(t\) appeared in document \(d\). The term frequency \(f_{t,d}\) is given as:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-tf-1400x444.png&quot; srcset=&quot;    /assets/resized/search-tf-480x152.png 480w,    /assets/resized/search-tf-800x254.png 800w,    /assets/resized/search-tf-1400x444.png 1400w,/assets/img/search-tf.png 1590w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 4: Term frequency.
&lt;/div&gt;

&lt;p&gt;Inverse document frequency measures how rare \(t\) is across the corpus \(D\). Given \(N = D\) as the total number of documents in the corpus and \(n_t\) as the number of documents having \(t\), the \(idf(t,D)\) can be calculated as:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-idf-1400x444.png&quot; srcset=&quot;    /assets/resized/search-idf-480x152.png 480w,    /assets/resized/search-idf-800x254.png 800w,    /assets/resized/search-idf-1400x444.png 1400w,/assets/img/search-idf.png 1590w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 5: Inverse document frequency.
&lt;/div&gt;

&lt;p&gt;Then we multiply them together to get the tf-idf score:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-tf-idf-1400x631.png&quot; srcset=&quot;    /assets/resized/search-tf-idf-480x216.png 480w,    /assets/resized/search-tf-idf-800x361.png 800w,    /assets/resized/search-tf-idf-1400x631.png 1400w,/assets/img/search-tf-idf.png 1632w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 6: tf-idf final score.
&lt;/div&gt;

&lt;h2 id=&quot;calculate-tf-idf-score-for-new-query&quot;&gt;Calculate tf-idf score for new query&lt;/h2&gt;

&lt;p&gt;Say that your system is running in production, how does it work when you have new query coming in? For term frequency (tf) we need to calculate it real-time. For idf, we can just use the precomputed idf. See the illustration below:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/search-rerank-1400x510.png&quot; srcset=&quot;    /assets/resized/search-rerank-480x175.png 480w,    /assets/resized/search-rerank-800x291.png 800w,    /assets/resized/search-rerank-1400x510.png 1400w,/assets/img/search-rerank.png 1998w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 7: Reranked list with tf-idf score.
&lt;/div&gt;

&lt;p&gt;Once we have the tf-idf vector, we still need to calculate the similarity between the query and the matched product tf-idf vectors. This will result in a complexity of \(\mathcal{O}(m * k)\) where m is the number of matched products and k is the complexity of the similarity metrics (cosine, euclidean, etc). To further speed up this process, we can use approximate nearest neighbor (ANN) which runs in \(\mathcal{O}(\log m * k)\). The details of ANN is out of the scope of this post.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;closing&quot;&gt;Closing&lt;/h1&gt;

&lt;p&gt;In the next post we will see other techniques involving retrieval and reranking. Stay tuned and thanks for reading!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cbrinton.net/ECE20875-2020-Spring/W10/ngrams.pdf&quot;&gt;Image source&lt;/a&gt; for Figure 4,5 and 6.&lt;/p&gt;</content><author><name></name></author><summary type="html">Have you ever wondered how search engine works? How can they match a query with millions of documents super fast and return them in a personalized way for each users? There are a lot of engineering techniques that power a search engine.</summary></entry><entry><title type="html">Uncertainty in the parameters of linear regression</title><link href="https://rezkaaufar.github.io/blog/2022/uncertainty-in-linear-regression/" rel="alternate" type="text/html" title="Uncertainty in the parameters of linear regression" /><published>2022-03-06T00:00:00+07:00</published><updated>2022-03-06T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2022/uncertainty-in-linear-regression</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2022/uncertainty-in-linear-regression/">&lt;p&gt;I recently found out that linear regression assumed that the output variable comes from normal distribution, which consequently turns the coefficient to have probabilistic interpretation. I was confused at first because I was taught linear regression from a machine learning model perspective: input some features and linear regression will fit a line that minimizes a certain cost function such as root mean squared error (RMSE) and then we use that for prediction. I went blank when I realized that there are probabilistic metrics associated with each coefficient. For example, if we use python libraries such as statmodels, it is going to show these probabilistic metrics.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statsmodels.api&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_rdataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Duncan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;carData&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'prestige'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'education'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'income'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/statsmodels-output-800x480.png&quot; srcset=&quot;    /assets/resized/statsmodels-output-480x288.png 480w,    /assets/resized/statsmodels-output-800x480.png 800w,/assets/img/statsmodels-output.png 1352w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: Example output of statsmodels.
&lt;/div&gt;

&lt;p&gt;Where does the confidence interval parameter come from? What about the std error, t statistics, and the p-value that is associated with each coefficient? Where do they come from? In this post we are going to take a look on how does this probability metrics came about.&lt;/p&gt;

&lt;h1 id=&quot;random-variables-in-linear-model&quot;&gt;Random variables in linear model&lt;/h1&gt;

&lt;p&gt;Probabilistic metrics exist with the notion of random variables. In linear regression, the variable of interest \(y\) that we want to predict is assumed to be generated from a normal distribution. In mathematical form, it looks like this:&lt;/p&gt;

\[\mu = X w_{true}\]

\[y \sim \mathcal{N}(\mu, \epsilon)\]

&lt;p&gt;This form can be rewritten as:&lt;/p&gt;

\[y = X w_{true} + \epsilon\]

\[\epsilon \sim \mathcal{N}(0, \mathbb{I})\]

&lt;p&gt;where \(X\) is our observed dataset, \(w_{true}\) is the true parameter that we cannot observe, and \(\epsilon\) is an independent noise.&lt;/p&gt;

&lt;p&gt;Why does it looks like this? Why does we have to assume that \(y\) sampled from a normal distribution? The short answer is because we assume linear regression to have this property. In reality, we will never know the value of \(w_{true}\), hence we want to approximate \(w_{true}\) by looking at the observed data \(X\). To do that, we introduce a new variable called \(w_{opt}\), the parameter that we can calculate from observed data. I would assume the reader is familiar with the closed form solution to find the optimal \(w_{opt}\) that approximates \(w_{true}\). The equation is given as:&lt;/p&gt;

\[w_{opt} = (X^T X)^{-1} X^T Y\]

&lt;p&gt;where the \(Y\) is the label observations in the data.
Notice the difference here: \(y\) is a random variable sampled from a normal distribution, whereas \(Y\) is the label observations in the data. We assume that the observed \(Y\) does not equal to \(X w_{true}\), but rather to \(X w_{true}\) plus some corrupted gaussian noise \(\epsilon\). Hence, we further assume that \(Y\) is the observations that we get from sampling the random variable of interest \(y\).&lt;/p&gt;

&lt;p&gt;If we look closer to the equation above, we will notice another thing: \(w_{opt}\) is calculated by linearly transforming two components: \(X\) and \(Y\). Since we model \(Y\) as a sample from the random variable \(y\), we can introduce another random variable \(\hat{w}\) that is calculated as:&lt;/p&gt;

\[\hat{w} = (X^T X)^{-1} X^T y\]

&lt;p&gt;\(\hat{w}\) represents a distribution of learnt parameter values. \(w_{opt}\), the variable that we use to approximate \(w_{true}\), can be seen as a sample from the distribution of learn parameter values \(\hat{w}\). This is because \(\hat{w}\) is defined as a linear transformation from the random variable \(y\), with \((X^T X)^{-1} X^T\) being the transformer matrix. And since \(Y\) is a sample from \(y\), \(w_{opt}\) is defined by applying the same transformation to the sample \(Y\).&lt;/p&gt;

&lt;h1 id=&quot;probability-density-function-for-hatw&quot;&gt;Probability density function for \(\hat{w}\)&lt;/h1&gt;

&lt;p&gt;Now we want turn \(\hat{w}\) into a probability density function. To get that, we can apply multivariate gaussian linear transformation rule to \(y \sim \mathcal{N}(\mu, \epsilon)\). I will not go into the details of the derivation in this post. For those interested, please see &lt;a href=&quot;https://towardsdatascience.com/where-do-confidence-interval-in-linear-regression-come-from-the-case-of-least-square-formulation-78f3d3ac7117&quot;&gt;here&lt;/a&gt;. Applying the transformation rule yields:&lt;/p&gt;

\[\hat{w} \sim N(w_{true}, (X^T X)^{-1} \eta^2)\]

&lt;p&gt;where \(\eta^2\) is the variance of each single random variable \(\epsilon\). It is defined by&lt;/p&gt;

\[\epsilon \sim \mathcal{N}(0, \mathbb{I} \eta^2)\]

&lt;p&gt;where \(\mathbb{I}\) is the identity matrix. In this case, \(\epsilon\) that we introduce in \(y \sim \mathcal{N}(\mu, \epsilon)\) is a multivariate Gaussian noise where it represents noise that is independent at each data point. Hence, the dimension of \(\eta^2\) is \(n\), where \(n\) is the number of data points.&lt;/p&gt;

&lt;p&gt;This leaves us with two unknown parameters that we need to define, namely \(w_{true}\) and \(\eta^2\), before we can get the probabilistic metrics out of \(\hat{w}\).&lt;/p&gt;

&lt;p&gt;For \(w_{true}\), we use \(w_{opt}\) as it is only sample that we observed in the training data. For \(\eta^2\), we need an observable value for the calculation. Since we already know that \(\hat{w}\) is transformed by the random variable \(y\), we use the variance of \(y\) to represent the noise part for unknown parameters \(\eta^2\). By definition, the variance of \(y\) is the same as the variance of \(\epsilon\) which is the same as the variance of \(\eta^2\). 
The variance of \(y\) can be calculated by taking the predicted value \(\hat{Y} = X w_{opt}\) versus the observed value \(Y\). Plugging this into a standard deviation formula, we get:&lt;/p&gt;

\[\eta^2 = \frac{1}{n-1} (\hat{Y} - Y)^T (\hat{Y} - Y)\]

&lt;p&gt;Note that \(\eta^2\) becomes a scalar now. That’s it! We can now proceed to look at each of the probabilistic metrics&lt;/p&gt;

&lt;h2 id=&quot;standard-deviation&quot;&gt;Standard deviation&lt;/h2&gt;

&lt;p&gt;We have defined this above. The standard deviation of our weight distribution is given by \((X^T X)^{-1} \eta^2\). The \((X^T X)^{-1}\) matrix is of p x p dimension and \(\eta^2\) is a scalar, yielding a p x p matrix, where \(p\) is the number of features that we have. The variance of each feature is at the main diagonal of this matrix.&lt;/p&gt;

&lt;h2 id=&quot;confidence-interval&quot;&gt;Confidence interval&lt;/h2&gt;

&lt;p&gt;Since \(\hat{w}\) is a multivariate Gaussian random variable, the confidence interval for each univariate random variable in \(\hat{w}\) is just some standard deviation away from its mean. We use the standard deviation parameter that we have computed above to calculate the confidence interval. For the mean, we use each elements in the \(w_{opt}\) vector.&lt;/p&gt;

&lt;h2 id=&quot;t-statistic-and-p--t&quot;&gt;T-statistic and \(P &amp;gt; t\)&lt;/h2&gt;

&lt;p&gt;These two metrics measure how likely the mean of the parameter is \(0\). Having a \(0\) mean indicates that the feature does not contribute to predicting the target variable \(Y\). The \(P &amp;gt; t\) is the p-value telling us how far is our mean parameter from \(0\), represented by t-statistics. High p-value tells us that the parameter is unlikely to be meaningful for the prediction, whereas low p-value tells us that the parameter is likely to have high contribution to the prediction.&lt;/p&gt;

&lt;p&gt;We calculate the t-statistics of the feature by:&lt;/p&gt;

\[t_j = \frac{\mu_j - 0}{\eta_j}\]

&lt;p&gt;where \(\mu_j\) is the j-th feature mean and \(\eta_j\) is the j-th standard deviation of the j-th feature. To get the p-value of the j-th feature we evaluate the t-statistics under \(\mathcal{N}(0,1)\)&lt;/p&gt;

&lt;h1 id=&quot;closing&quot;&gt;Closing&lt;/h1&gt;

&lt;p&gt;There were more stuff going on under linear regression that I hadn’t realized before. I hope this post can help you in understanding where does the probabilistic metrics came from.&lt;/p&gt;</content><author><name></name></author><summary type="html">I recently found out that linear regression assumed that the output variable comes from normal distribution, which consequently turns the coefficient to have probabilistic interpretation. I was confused at first because I was taught linear regression from a machine learning model perspective: input some features and linear regression will fit a line that minimizes a certain cost function such as root mean squared error (RMSE) and then we use that for prediction. I went blank when I realized that there are probabilistic metrics associated with each coefficient. For example, if we use python libraries such as statmodels, it is going to show these probabilistic metrics.</summary></entry><entry><title type="html">Hypothesis testing with binomial distribution in an AB test</title><link href="https://rezkaaufar.github.io/blog/2021/ab-test-hypothesis-testing-binomial/" rel="alternate" type="text/html" title="Hypothesis testing with binomial distribution in an AB test" /><published>2021-12-28T00:00:00+07:00</published><updated>2021-12-28T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/ab-test-hypothesis-testing-binomial</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/ab-test-hypothesis-testing-binomial/">&lt;p&gt;In the previous post we talked about how does frequentist hypothesis testing work in an AB test using a normal distribution. In this post we are going to look at the hypothesis testing if your variable of interest is binary using a binomial distribution. Let’s get started!&lt;/p&gt;

&lt;h1 id=&quot;samples--parameter-inference&quot;&gt;Samples &amp;amp; Parameter Inference&lt;/h1&gt;

&lt;p&gt;Let’s say that we have completed an AB test and we have sample size \(n=10000\) for both the control and variant group. The control have \(ns_c=5500\) and the variant have \(ns_v=5700\), which represents the number of success we get.&lt;/p&gt;

&lt;p&gt;To do a hypothesis test, we need to infer the parameter of the binomial distribution for both the control and variant group. In binomial distribution, the parameter is \(\theta\), which represents the probability of getting a positive outcome in a trial. Based on the data, we can infer that:&lt;/p&gt;

\[p_c = \frac{ns_c}{n} = \frac{5500}{10000} = 0.55\]

\[p_v = \frac{ns_v}{n} = \frac{5700}{10000} = 0.57\]

&lt;h1 id=&quot;binomial-distribution--significance-testing&quot;&gt;Binomial Distribution &amp;amp; Significance Testing&lt;/h1&gt;

&lt;p&gt;Now we want to determine whether the difference between control and variant group is significant enough so that we can decide which group we want to apply in our system. To do this, we need to find out what is the probability of getting 5700 success (the variant group parameter) assuming that the control distribution with \(p_c=0.55\) is true. Mathematically, it is defined as:&lt;/p&gt;

\[a(ns) = \sum_{K=ns}^N {N \choose K} P_{0}^{K} (1 - P_{0}^{K})^{N-K}\]

&lt;p&gt;where in this case \(ns\) is the variant group successes \(ns_v\) and \(P_0\) is the control group binomial distribution parameter \(p_c\).&lt;/p&gt;

&lt;p&gt;In plain words, the formula tells us what is the probability of observing the event plus the probability of observing other events that are equally rare and more extreme. In this case, the event is the variant group successes \(ns_v\). Also note that I am using a one-sided test because in an AB test we only care about getting an improvement. We don’t care if the variant group successes is significantly worse than control group success, even though by statistical definition it still counts as significant.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binom_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.55&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alternative&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'greater'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;2.9637380107656557e-05&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Using python code above, we can see that we get a low p-value, which tells us that it is unlikely to get 5700 successes assuming that the control distribution is true. Hence we can conclude that the variant group yields better conversion.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/resized/gaussian-approx-binomial-480x300.png&quot; srcset=&quot;    /assets/resized/gaussian-approx-binomial-480x300.png 480w,/assets/img/gaussian-approx-binomial.png 576w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: Gaussian approximation of binomial distribution of both the control and variant group.
&lt;/div&gt;

&lt;p&gt;Figure 1 shows the gaussian approximation of both the control and variant binomial distributions. By theory, we know that we can &lt;a href=&quot;https://online.stat.psu.edu/stat414/lesson/28/28.1&quot;&gt;approximate binomial distribution with a normal distribution&lt;/a&gt;. In math notation, the parameter of the normal distribution can be calculated as:&lt;/p&gt;

\[\mu = np\]

\[\sigma = np(1-p)\]

&lt;p&gt;where \(n\) is the number of trials and \(p\) is the probability of success in a trial.&lt;/p&gt;

&lt;p&gt;We can use \(\sigma\) to calculate the confidence interval around the binomial parameter:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.55&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'95% confidence interval of our binomial distribution is between &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; and &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;our&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binomial&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distribution&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;between&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.54&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.56&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The confidence interval reinforces our initial findings that getting \(0.57\) is unlikely assuming that \(p_c=0.55\) is true.&lt;/p&gt;

&lt;h1 id=&quot;closing&quot;&gt;Closing&lt;/h1&gt;

&lt;p&gt;Thanks for reading my blog post! Hit me on twitter &lt;a href=&quot;https://twitter.com/rezkaaufar&quot;&gt;@rezkaaufar&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">In the previous post we talked about how does frequentist hypothesis testing work in an AB test using a normal distribution. In this post we are going to look at the hypothesis testing if your variable of interest is binary using a binomial distribution. Let’s get started!</summary></entry><entry><title type="html">Hypothesis testing with normal distribution in an AB test</title><link href="https://rezkaaufar.github.io/blog/2021/ab-test-hypothesis-testing/" rel="alternate" type="text/html" title="Hypothesis testing with normal distribution in an AB test" /><published>2021-11-21T00:00:00+07:00</published><updated>2021-11-21T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/ab-test-hypothesis-testing</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/ab-test-hypothesis-testing/">&lt;p&gt;AB test is one of the integral parts that a data scientist need to master. One of the goals of doing AB test is to better inform the team to help them make decision. How can we do that? In a hypothetical scenario, let’s say that we have done an AB test and we have gathered two experiment data: one for variant A (baseline) and one for variant B. One of the things that we had to consider is how to analyze the data after the test had run? How do we decide which variant is better? Deciding which variants are better is crucial because ultimately this information is going to influence the team decisions.
In this post we are going to see an overview on how we can derive conclusion of an experiment based on the frequentist school of statistic. We will use normal distribution as a distribution to work with as it is one of the most common distribution that we might encounter in a real life AB test.&lt;/p&gt;

&lt;h1 id=&quot;before-hypothesis-testing&quot;&gt;Before hypothesis testing&lt;/h1&gt;
&lt;p&gt;Before doing hypothesis testing, the first thing that we need to understand is that we only have samples from our AB test, not the true underlying distribution. Ideally, we want to do the hypothesis testing using the true underlying distribution. In reality, we do not know anything about the true underlying distribution. We do not know their distribution, let alone the parameters of the distribution. All we can do is to make an assumption about: 1) the form of the true distribution and 2) the approximation of the true parameter of the assumed distribution. The former is mostly decided by looking at the problem and data format, whereas the latter is based on the data samples. For example. if we are working with a normal distribution, then we need to know the true mean. We can then make an assumption that the mean can be approximated with our samples. Same thing can also be said for the standard deviation.&lt;/p&gt;

&lt;h1 id=&quot;samples&quot;&gt;Samples&lt;/h1&gt;
&lt;p&gt;Say that we are making an intervention to our systems and our metric of interest are a continuous value, such as response time of a customer, time it takes for customer to complete an order, etc. We have gathered the experiment data and we assume that the true baseline has mean=0.1 and the true variant b has mean=-0.1.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kde&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edgecolor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;&quot; srcset=&quot;/assets/img/freq-ab-sample.png 432w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1 data-zoomable&quot; src=&quot;/assets/img/freq-ab-sample.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 50%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: Example of an AB test sample from two variants.
&lt;/div&gt;

&lt;h1 id=&quot;inferring-the-parameter-standard-error&quot;&gt;Inferring the parameter: standard error&lt;/h1&gt;
&lt;p&gt;First we need to infer the parameter of the distribution. In real life we do not know the true parameter, so here we just take the mean and calculate the standard deviation and assume that these values are the true parameter:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.10209145722536886&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.004581515836704&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.10367983213074679&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.008924455645851&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;With the parameter information at hand, we can plot both distribution with their confidence interval:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;a_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a_se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a_ci&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;b_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b_se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b_ci&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;A 95% CI&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;B 95% CI&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;&quot; srcset=&quot;/assets/img/freq-ab-sample-ci.png 432w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/freq-ab-sample-ci.png&quot;  style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 2: The 95% confidence interval for mean of both baseline and variant b.
&lt;/div&gt;

&lt;p&gt;Since we only have one mean, which is our sample mean, we use standard error to create a confidence interval around the sample mean. The confidence interval relies on a theory called central limit theorem. This theorem states that means of experiments are normally distributed. The standard error of the mean serves as our estimate of the distribution of the experiment means. So, if we multiply it by 2 and add and subtract it from the mean of one of our experiments, we will construct a 95% confidence interval for the true mean. Note that we don’t need to restrict ourselves to the 95% confidence interval.&lt;/p&gt;

&lt;p&gt;What we can see from Figure 2 is that the 95% CI of the variants don’t overlap. The lower end of the CI for variant b is above the upper end of the CI for baseline. This is evidence that our result is not by chance, and that the true mean for variant b is higher than the true mean for baseline. In other words, we can conclude that there is a significant increase in our metric when switching from baseline to variant b.&lt;/p&gt;

&lt;h1 id=&quot;inferring-the-parameter-bootstrap&quot;&gt;Inferring the parameter: bootstrap&lt;/h1&gt;
&lt;p&gt;There is another way to estimate the interval of the true mean. Ideally when we want to estimate the interval of the true mean, we would like to be able to simulate an experiment with multiple datasets. In other words, we would like to be able to get multiple sample means from different samples to get the mean of means. Using this mean of means, we can then create a confidence interval. This technique is commonly known as bootstrap. I am not going into the bootstrap detail in this post.&lt;/p&gt;

&lt;h1 id=&quot;concluding-the-test-using-hypothesis-testing&quot;&gt;Concluding the test using hypothesis testing&lt;/h1&gt;
&lt;p&gt;To solidify our conclusion regarding confidence interval, we can state a hypothesis test: is the difference in means statistically different from zero (or any other value)? To achieve this, we need to test our the difference between the two distributions against a null hypothesis. The null hypothesis in this case is a zero difference in mean, represented by a zero-centered normal distribution. To calculate the difference between the two distributions, we recall that the sum or difference of 2 independent normal distributions is also a normal distribution. The resulting mean will be the sum or difference between the two distributions, while the variance will always be the sum of the variance.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.96&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.96&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.16824798031433202&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.22381185401183407&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;95% CI&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;&quot; srcset=&quot;/assets/img/freq-ab-95-ci.png 432w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/freq-ab-sample-ci.png&quot;  style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 3: The 95% confidence interval for the difference between the two distributions.
&lt;/div&gt;

&lt;p&gt;With this at hand, we can say that we are 95% confident that the true difference between the baseline and variant b group falls between -0.22 and -0.17. We can also construct a z statistic by dividing the difference in mean by the standard error of the differences. The z statistic is a measure of how extreme the observed difference is. To further test our hypothesis that the difference between the two means is statistically different, we will assume that the opposite is true, that is, the difference is zero. This is our assumed null hypothesis. Under the null hypothesis, if the difference is indeed zero, we will see the z statistic falls between 2 standard deviations of the mean 95% of the time. If the z statistic falls outside the 2 standard deviations, then we can reject the null hypothesis and conclude that there is a difference between our two distributions.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff_se&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Standard Normal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Z statistic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;C1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        


&lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;&quot; srcset=&quot;/assets/img/freq-ab-z-statistics.png 432w&quot; data-zoomable=&quot;&quot; /&gt;

        &lt;!-- &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/freq-ab-sample-ci.png&quot;  style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot;&gt; --&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 4: The z-score of our differences plotted over the null hypothesis.
&lt;/div&gt;

&lt;p&gt;This looks like a highly extreme value. It is below -2 which means there is less than a 5% chance that we would see such an extreme value if there were no difference in the groups. The probability of the z statistic plus the probability of observing more extreme values under the null hypothesis are mostly known as p-values. P-values measure how unlikely it is that we are seeing a measurement if the null hypothesis is true. In our case above, we can see from the graph that our p-value is extremely low (\(2.5*10^{-45}\) to be exact). This again leads us to conclude that switching from baseline to variant b causes a statistically significant improvement in our metric.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;P-value:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ttest_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# the two code above will yield the same value&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h1 id=&quot;closing&quot;&gt;Closing&lt;/h1&gt;
&lt;p&gt;To the naked eye, this might shock us as the sample distribution highly overlaps in Figure 1. Personally. I think that p-value is just one component that we can calculate to help make a decision. It should not be the sole reason to decide on a problem. There may be a case where getting an improvement from -0.01 to 0.01 is not necessarily a good thing. So please be careful and know the downside of using p-value.&lt;/p&gt;

&lt;p&gt;Thanks for reading my blog post. In the next post, I will talk about frequentist hypothesis testing using a bernoulli distribution. Stay tuned!&lt;/p&gt;

&lt;p&gt;Contact me on twitter &lt;a href=&quot;https://twitter.com/rezkaaufar&quot;&gt;@rezkaaufar&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">AB test is one of the integral parts that a data scientist need to master. One of the goals of doing AB test is to better inform the team to help them make decision. How can we do that? In a hypothetical scenario, let’s say that we have done an AB test and we have gathered two experiment data: one for variant A (baseline) and one for variant B. One of the things that we had to consider is how to analyze the data after the test had run? How do we decide which variant is better? Deciding which variants are better is crucial because ultimately this information is going to influence the team decisions. In this post we are going to see an overview on how we can derive conclusion of an experiment based on the frequentist school of statistic. We will use normal distribution as a distribution to work with as it is one of the most common distribution that we might encounter in a real life AB test.</summary></entry><entry><title type="html">Causal model with bayesian network</title><link href="https://rezkaaufar.github.io/blog/2021/structural-causal-model/" rel="alternate" type="text/html" title="Causal model with bayesian network" /><published>2021-08-26T00:00:00+07:00</published><updated>2021-08-26T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/structural-causal-model</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/structural-causal-model/">&lt;p&gt;In this &lt;a href=&quot;https://rezkaaufar.github.io/blog/2021/language-of-causal-model/&quot;&gt;previous post&lt;/a&gt;, I wrote about the language of causal inference via counterfactuals. I briefly mentioned that there are at least two ways to capture the causal effect: counterfactuals and structural causal model. In this post, we are going to look at structural causal model and how we can use it to simulate what would happen if we do an intervention to a particular variable of interest. Please do note that both counterfactuals and structural causal model are highly overlapped and they share the same underlying concepts.&lt;/p&gt;

&lt;h1 id=&quot;simpsons-paradox-in-an-acyclic-directed-graph&quot;&gt;Simpson’s paradox in an acyclic directed graph&lt;/h1&gt;
&lt;p&gt;I have mentioned about simpson’s paradox briefly in my previous blog post. Here I am going to illustrate another perspective on how simpson’s paradox can affect the result of classical machine learning. Consider a (true) causal graph below.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-graph.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: An example of a true causal graph between 5 variables
&lt;/div&gt;

&lt;p&gt;Assume that we have data with these 5 variables in a spreadsheet style (think pandas dataframe) and we are tasked to find the effect on how exposure to sun (\(T\)) on the illness (\(Y\)). Without any knowledge of causal inference, we might think to just incorporate \(T\) as feature and create a linear regression model on the label \(Y\). Once we have the model, we use the coefficient to gauge and measure the relationship between exposure to sun and illness. If the coefficient is a positive number, then it tells us that there is a positive relationship, and vice versa if the coefficient is a negative number.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-regression.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 2: Results of two linear regressions using different features. (&lt;a href=&quot;https://www.youtube.com/watch?v=5JsFZbGqJzc&amp;amp;t=1516s&amp;amp;ab_channel=ODSAIGlobal&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;p&gt;Looking at Figure 2 above, if we use \(T\) as the single feature to predict \(Y\), we got test RMSE of 10 and a coefficient of 0.99, meaning that there is a positive relationship between exposure to sun and illness. But if we were to add \(C\) (type of car owned) as feature, then we would have an even better test RMSE of 7.7, hinting that type of car owned is helpful in predictive power. But if we inspect the coefficient, we see that now \(T\) and \(Y\) have a negative relationship, whereas \(C\) and \(Y\) have a positive relationship. How can this happen? How can knowing the type of car owned results in more predictive power to illness? To the naked eye, this seems pretty unintuitive. But if we know the true causal graph we will immediately realized that knowing \(C\) indirectly tells us the age of the person, which gives it the predictive power to illness. This is another example of simpson’s paradox in a acyclic directed graph which we can use to distinguish flow of correlation vs causation.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;bayesian-network&quot;&gt;Bayesian Network&lt;/h1&gt;

&lt;p&gt;We know that strong correlation between variables do not imply a causal effect. With counterfactuals, we introduce potential outcomes \((Y1, Y0)\) to be able to capture the causal effect. With structural causal model (SCM), the goal is to model the causal interdependencies between variables. One tool that we can use to achieve this is to use probabilistic graphical models (PGM). With PGM, we can model the relationships between features. PGM as a term encompasses many different approaches. In our case, one of the graph models that we can use to capture causal model is a bayesian network. Bayesian network is a directed acyclic graph that captures the interdependencies between variables. Nodes represent random variables, whereas edges represent relationships (the conditional probabilities) between variables.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-bn-example.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 3: Illustration of a bayesian network
&lt;/div&gt;

&lt;p&gt;In a bayesian network, the value of a node is independent of the rest of the variables in the graph given its parents. The relationship between arbitrary nodes are not necessarily causal. Therefore, we need to assume that the directed edges are the actual causal effect. This is where the unconfoundedness assumption plays in SCM. We need to believe and be sure that the bayesian network that we build have no unmeasured confounders.&lt;/p&gt;

&lt;h2 id=&quot;how-to-build-bayesian-network&quot;&gt;How to build bayesian network?&lt;/h2&gt;
&lt;p&gt;So now we might ask: how do we build this bayesian network? If we have a lot of features, do we need to manually specify the causal relationships between the features that we have? There are some ways in which we can utilize correlation to automatically build the bayesian network, such as the &lt;a href=&quot;https://arxiv.org/abs/1803.01422&quot;&gt;NOTEARS&lt;/a&gt; algorithm. This automatic training is also known as structure learning. However, we can’t just blindly use the result. It’s better to have an expert to review the structure and fix the relationship (add, remove, or flip edges) in the bayesian network if deemed necessary.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-bn-build.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 4: Steps to build a bayesian network
&lt;/div&gt;

&lt;p&gt;Figure 4 above shows the steps in building a bayesian network:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;First, we can use some algorithm (NOTEARS) to automatically build edges between our variables.&lt;/li&gt;
  &lt;li&gt;As a consequence of the learning process, the edges have weights. Hence we can remove some edges that are below a certain threshold. This results in an initial causal structure build automatically from the algorithm.&lt;/li&gt;
  &lt;li&gt;We can then further proceed to fix the causal structure by flipping, removing, or adding edges based on our domain knowledge.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-lies-underneath-bayesian-network&quot;&gt;What lies underneath bayesian network?&lt;/h2&gt;
&lt;p&gt;In the classical literature, bayesian networks are mostly either fully discrete or fully gaussian. This means that all the nodes in the graph are either discrete or continuous. The reason is because of closure properties: fully discrete allows us to model the conditional probability distribution with conditional table and they are all jointly multinomial random variable, whereas fully gaussian allows every operation (conditional, marginal, etc) to always result in another gaussian. There are other approaches where we use a non-parametric version of bayesian network which allows us to work flexibly with different types of distributions.&lt;/p&gt;

&lt;h2 id=&quot;parameter-estimation-in-bayesian-network&quot;&gt;Parameter estimation in bayesian network&lt;/h2&gt;
&lt;p&gt;The structure tells us the causal relationships, and for each of these relationships, there is a distribution which tells us the probability of attaining a certain state given for any variable given the states of the parent node. In a fully discrete bayesian network, the size of the conditional probability table would be the number of states of current node multiplied by the parents state. This would be total parameter that we need to estimate from data. To estimate these parameters, one can use maximum likelihood estimation (usually just involves taking counts and fractions) which produces a point estimate or use bayesian estimation and allows us to put a prior belief on the estimate.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-bn-trained.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 5: A conditional probability distributions for each node in bayesian network
&lt;/div&gt;

&lt;p&gt;Figure 5 shows the illustration after fitting the parameters of our 3 variables on the observational data. Each node is governed by a conditional probability. If a variable does not have any parents, then it’s just its own probability.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;the-operation-in-bayesian-network&quot;&gt;The operation in bayesian network&lt;/h1&gt;
&lt;p&gt;With a bayesian network defined, one might ask: what can do with it? There are two operations that we can apply on a bayesian networks node: conditioning and intervention. Do note that conditioning is not always the same as the causal effect, that is why it is better to always do an intervention if we are able to and especially if we want to gain insight using the bayesian network.&lt;/p&gt;

&lt;h2 id=&quot;conditioning&quot;&gt;Conditioning&lt;/h2&gt;
&lt;p&gt;Conditioning is an observational inference: having observed the data that we have, what would the probability of a certain variable be given that we observe some parents state. Since conditioning is observational, we can do conditioning between any arbitrary nodes without having to follow the directed edge (yes including between nodes that doesn’t have any directed arrows). Conditioning is usually done in a setting where one cannot do an intervention. 
In conditioning, we can have a non-causal correlation flowing from one node to another node if we are not careful, leading to an incorrect interpretation. In other words, conditioning between arbitrary nodes without regarding the causal effect might lead to a spurious correlation. Consider this case below:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-ass-caus.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 70%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 6: Association vs causation in a graph (&lt;a href=&quot;https://www.bradyneal.com/causal-inference-course&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;p&gt;The true causal effect from treatment \(T\) to outcome \(Y\) flows through \(M1\) and \(M2\). However, in the case above there are two other paths in which non-causal correlation can flow from \(T\) to \(Y\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(W1\), \(W2\), \(W3\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(X1\), \(X2\), \(X3\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The \(W\) path is known as confounder path. In bayesian network, confounder path can mess with the treatment effect because it affect how treatment \(T\) is assigned, making \(Y\) also affected. The only way to measure the treatment effect correctly in this case is by conditioning on all possible confounder. In the case of bayesian network, if we intervene on \(T\), then the non-causal association in the W path is automatically blocked. If we cannot do an intervention and would want to derive treatment effect from observational data, then the W path needs to be conditioned on, otherwise the non-causal association will render the causal effect incorrect. In the \(W\) path, conditioning on children of colliders (either \(W1\) or \(W3\)) also blocks the non-causal association, so it doesn’t have to be on the confounder node.&lt;/p&gt;

&lt;p&gt;The \(X\) path is known as colliders. Contrary to the confounder, conditioning on the collider can make non-causal association flows through the path. We will not go into details but here is an excellent &lt;a href=&quot;http://corysimon.github.io/articles/berksons-paradox-are-handsome-men-really-jerks/&quot;&gt;example of colliders&lt;/a&gt;. The idea is that if we have colliders, we should not apply conditioning on that variable as it can mess with our interpretation.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-cond-intv.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 7: Visual illustration on the difference between conditioning and intervening (&lt;a href=&quot;https://www.bradyneal.com/causal-inference-course&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;h2 id=&quot;intervention&quot;&gt;Intervention&lt;/h2&gt;
&lt;p&gt;To gain insight from our model, we want to query our model under different observation. With intervention, we can replace the probability distributions of a certain state. If this state has a children, then we can simulate what would have happened to the children marginal probability if we do an intervention to the node. Unlike conditioning, intervention on a node will only affect its children according to the causal direction.
Figure 8 and 9 below shows how we can do an intervention to simulate the target variable.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-bn-before-intv.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 8: Marginal probability of getting high or low grades before doing an intervention
&lt;/div&gt;

&lt;p&gt;Figure 8 shows the calculation of the joint probability between Grade, Study, and School Support, and the marginal probability of Grade. Remember that \(P(S)\),  \(P(SS)\), and \(P(G \mid S, SS)\) are calculated from data. These are the parameters that we estimated after we have the causal structure. With the estimated parameter and causal structure, we calculate the marginal probability of Grade. This is the marginal probability that we learn from data before we do any intervention.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/scm-bn-after-intv.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 70%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 9: Marginal probability of getting high or low grades after doing an intervention on the study variable
&lt;/div&gt;
&lt;p&gt;Figure 9 shows how it would look like to Grade variable if we do an intervention on Study. Here we force \(P(S)\) to hold a certain value: in plain English we can interpret this as forcing everyone to Study. We can see after intervening, the marginal probability of Grade from 0.605 to 0.875 on the marginal probability \(P(G=High)\). This means that we can assume that if we nudge students to study more then it would yield better grades that is good for the school.&lt;/p&gt;

&lt;p&gt;Please note that when doing intervention, we assume that the change in the target variables marginal probability happens on the whole population. However, when we build the causal structure and fit the parameters for every variables, we do it on the observational data. So it’s important to make sure that we have enough data first. Ensuring that we have enough data is most commonly known as fulfilling the &lt;a href=&quot;https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf&quot;&gt;positivity/overlap&lt;/a&gt; assumption.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;recap-and-closing&quot;&gt;Recap and closing&lt;/h1&gt;
&lt;p&gt;In this post we cover structural causal model as a way to capture causal language. We have seen:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Simpson’s paradox in a graph.&lt;/li&gt;
  &lt;li&gt;Directed acyclic graph, especially bayesian network, as a structure to model both association and causation relationship between variables.&lt;/li&gt;
  &lt;li&gt;How to build bayesian network given data.&lt;/li&gt;
  &lt;li&gt;Condition and intervention as operations that we can apply in bayesian network.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks for reading this post! Contact me on twitter for feedback &lt;a href=&quot;https://twitter.com/rezkaaufar&quot;&gt;@rezkaaufar&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">In this previous post, I wrote about the language of causal inference via counterfactuals. I briefly mentioned that there are at least two ways to capture the causal effect: counterfactuals and structural causal model. In this post, we are going to look at structural causal model and how we can use it to simulate what would happen if we do an intervention to a particular variable of interest. Please do note that both counterfactuals and structural causal model are highly overlapped and they share the same underlying concepts.</summary></entry><entry><title type="html">Understanding the language of causal model</title><link href="https://rezkaaufar.github.io/blog/2021/language-of-causal-model/" rel="alternate" type="text/html" title="Understanding the language of causal model" /><published>2021-07-09T00:00:00+07:00</published><updated>2021-07-09T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/language-of-causal-model</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/language-of-causal-model/">&lt;p&gt;“Correlation does not imply causation”&lt;/p&gt;

&lt;p&gt;You might hear this jargon everywhere since it is quite pervasive if you work in data science/machine learning. Also, you might have seen this image about spurious correlation:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/corr-col.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 1: spurious correlation (&lt;a href=&quot;https://www.kaggle.com/general/187094&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;p&gt;But what does it mean, really? What does “correlation does not imply causation” really mean? Given a data \(X\) and a target variable \(Y\), can we estimate direct causal effect? If so, how can we know that we have modeled causation in a correct way? Is there a formal way to capture this English statement? Yes!&lt;/p&gt;

&lt;p&gt;In causal inference, there are at least two formal ways to discuss causation: one is based on counterfactuals (or potential outcomes) and the other one is based on causal directed acyclic graph (or structural causal model). The latter involves Judea Pearl’s do-calculus. For the rest of this post I am going to use the former, which is the language of counterfactuals to draw the intuition.
Okay, enough intro. The best way to start understanding why correlation \(\neq\) causation is to understand the simpson’s paradox.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;simpsons-paradox&quot;&gt;Simpson’s paradox&lt;/h1&gt;

&lt;p&gt;Imagine we are developing a treatment for both men and women. We want to know the causal effect of the treatment. Specifically, we want to draw a conclusion from the treatment with the following possibility:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Treatment is good for men (S1)&lt;/li&gt;
  &lt;li&gt;Treatment is good for women (S2)&lt;/li&gt;
  &lt;li&gt;Treatment is bad overall (S3)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, simpson’s paradox occurs when people equate probabilistic statements with the statements (S1), (S2), and (S3) above. How does the probabilistic statements look like? Consider the data below&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/table-causal.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Table 1: illustrative data
&lt;/div&gt;

&lt;p&gt;From the table, we have treatment \(T\) that is binary (given and not given), feature (or covariate) \(X\) that is also binary (men and women) and the outcome \(Y\) that is also binary (working and not working). The numbers in the column is the sum of treatment that is working (\(Y=1\)). Consequently, we have the probabilistic interpretation as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=1, X=1) = 0.15\) 
(Group 1)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=0, X=1) = 0.10\)
(Group 2)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=1, X=0) = 0.30\)
(Group 3)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=0, X=0) = 0.20\)
(Group 4)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=1) = 0.16\)
(Group 5)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=0) = 0.19\)
(Group 6)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From the probabilistic interpretation above, we can derive three key probabilistic statements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=1, X=1) - P(Y=1 | T=0, X=1) &amp;gt; 0\)
(P1)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=1, X=0) - P(Y=1 | T=0, X=0) &amp;gt; 0\)
(P2)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y=1 | T=1) - P(Y=1 | T=0) &amp;lt; 0\)
(P3)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember: simpson’s paradox occur when people equate probabilistic statements (P1-P3) with the English statements (S1-S3). We see from the example above, all (P1), (P2), and (P3) are true. But in causal inference, it is NOT possible for (S1), (S2), and (S3) to all be true. If the treatment is good for both men and women (S1-S2), then it should not be possible that the overall treatment is bad (S3). But why does our observation says otherwise? Again, the error is in equating (P1-P3) with (S1-S3).&lt;/p&gt;

&lt;p&gt;How does this happen then? Is it because of the sample size that is not comparable between groups? Well we can still have more or less the same sample size and still fall to simpson’s paradox (&lt;a href=&quot;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-notes/MIT6_S897S19_lec14note.pdf&quot;&gt;example&lt;/a&gt;). To understand why this is happening, we need to understand the effect of confounding variable.&lt;/p&gt;

&lt;h1 id=&quot;confounding-variable&quot;&gt;Confounding variable&lt;/h1&gt;
&lt;p&gt;Let’s take a closer look at Table 1. Do you notice a pattern in the treatment assignment? You can see that the there are more treated men than those who doesn’t receive treatment. On the other hand, there are less treated women than those who doesn’t receive treatment. We might wonder: gender probably affects the treatment assignment, therefore there are more men who received treatment than women, which led to non-comparable groups formed between men and woman. In this case, gender is a confounding variable. Confounding variable is a common cause that is both affecting the treatment and the treatment outcome. Usually confounding variable is unobserved.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/confound-graph.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 2: directed acyclic graph illustrating confounding variable (&lt;a href=&quot;https://www.bradyneal.com/slides/2%20-%20Potential%20Outcomes.pdf&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;p&gt;There is an information flow between the treatment to the outcome via the confounding variable, resulting in (P1-P3) to all be true. In this case, \(X\) is the confounding variable: the gender.&lt;/p&gt;

&lt;h1 id=&quot;correlation-does-not-imply-causation-in-a-formal-way&quot;&gt;Correlation does not imply causation (in a formal way)&lt;/h1&gt;
&lt;p&gt;To capture the English statements (S1-S3) above, we use counterfactuals. We start by introducing \((Y1, Y0)\) where \(Y1\) is the outcome if one is treated and \(Y0\) is the outcome if one is not treated. We observe:&lt;/p&gt;

\[Y = T Y1 + (1 - T) Y0\]

&lt;p&gt;To put it simply, \(Y1\) denotes the outcome I WOULD observe if I WERE to take the treatment, \(Y0\) denotes the outcome I WOULD observe if I WERE to not take the treatment, whereas \(Y\) denotes the outcome that I do observe just in the observational data. In reality, we never observe \(Y1\) and \(Y0\) in the observational data on any person, that is why when we derive conclusion DIRECTLY from Y, we observe the simpson’s paradox. We’ll see more details regarding counterfactuals in the next section.&lt;/p&gt;

&lt;p&gt;The correct translation of (S1-S3) is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y1=1 | X=1) - P(Y0=1 |X=1) &amp;gt; 0\) 
(C1)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y1=1 | X=0) - P(Y0=1 |X=0) &amp;gt; 0\) 
(C2)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(P(Y1=1) - P(Y0=1) &amp;lt; 0\) 
(C3)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These three statements cannot be all true. If the first two statements hold, then:&lt;/p&gt;

\[P(Y1=1) - P(Y0=1) = \sum_{x=0}^1 [P(Y1=1 | X=x) - P(Y0=1 | X=x)] P(x)\]

&lt;p&gt;This is why if the treatment is good for both men and women (S1-S2) , then it is not possible that the overall treatment is bad (S3).
In summary:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(C1) = (E1) \(\neq\) (P1)&lt;/li&gt;
  &lt;li&gt;(C2) = (E2) \(\neq\) (P2)&lt;/li&gt;
  &lt;li&gt;(C3) = (E3) \(\neq\) (P3)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and (E3) cannot be true if (E1) and/or (E2) hold.
In general, we have:&lt;/p&gt;

\[P(Y=1 | T=1, X=1) - P(Y=1 | T=0, X=1) \neq P(Y1=1 | X=1) - P(Y0=1 |X=1)\]

\[P(Y=1 | T=1, X=0) - P(Y=1 | T=0, X=0) \neq P(Y1=1 | X=0) - P(Y0=1 |X=0)\]

\[P(Y=1 | T=1) - P(Y=1 | T=0) \neq P(Y1=1) - P(Y0=1)\]

&lt;p&gt;In other words, correlation (left hand side) does not imply causation (right hand side). The left hand side can also be called the probabilistic quantity and the right hand side can be called causal quantity.&lt;/p&gt;

&lt;h1 id=&quot;counterfactuals&quot;&gt;Counterfactuals&lt;/h1&gt;
&lt;p&gt;I mentioned above that in order to capture the causal statements, we can use counterfactuals (or potential outcome). But what does it mean? In our binary treatment example, counterfactuals are the outcomes that we could have observed if we can give treatment and not give treatment to a person simultaneously. Ideally, to measure the true causal effect, we would want to put everyone in the population in both the treatment group and control group(s). Consider the men group in Table 1: the true causal effect is the difference between all 1450 people for the treatment group and all 1450 people for the control group. In other words, we want both the outcome for treatment and no treatment to be available for everyone. But in this case (and almost always) the counterfactuals cannot be observed, hence we take the naive difference between n=1400 and n=50.&lt;/p&gt;

&lt;p&gt;So how do we derive the correct causal effect then? How can we get \(Y1\) and \(Y0\) so that we can reliably say that my treatment has an effect? Do we have to fill in all the counterfactuals so that we have the same number of instances between groups? As far as I understand, there are two ways we can derive causal effect reliably:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Randomized controlled trial (or AB Test).&lt;/li&gt;
  &lt;li&gt;Conditioning on all possible confounding variables.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The former usually does not involve in filling all the counterfactuals (which we’ll see more below). The latter approach is used in a situation where it is almost impossible to do randomized controlled trials (e.g. telling non-smoker to smoke to determine the causal effect of smoking to impotence). The latter is also mostly used on observational data. Furthermore, in the latter case we can take it further by filling the counterfactuals to get the best causal effect estimate.&lt;/p&gt;

&lt;h1 id=&quot;randomized-controlled-trials&quot;&gt;Randomized controlled trials&lt;/h1&gt;
&lt;p&gt;RCT/AB test removes the effects of confounding to the treatment. Directed edge from \(X-&amp;gt;T\) is removed.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/rct-causal.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 3: effects of RCT on the edge between confounding to treatment (&lt;a href=&quot;https://www.bradyneal.com/slides/2%20-%20Potential%20Outcomes.pdf&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;p&gt;This means that the treatment assignments are now purely random. Consequently, this makes \(T\) independent of \((Y1, Y0)\), or in other words, the treatment does not affect the potential outcome anymore. Note the difference: treatment \(T\) still affect the actual outcome \(Y\) but the treatment DOES NOT affect the potential outcome \(Y1\), \(Y0\). For more intuition regarding this I highly recommend checking out &lt;a href=&quot;https://www.bradyneal.com/causal-inference-course&quot;&gt;Brady Neal’s causal inference course&lt;/a&gt;.
With the independence, we have&lt;/p&gt;

\[P(Y=1 | T=1, X=x) = P(Y1 = 1 | X=x)\]

&lt;p&gt;hence we can assume that the probabilistic quantity (P1-P1) is now the same as the causal quantity (C1-C3). Therefore, we can derive the causal effect directly from the probabilistic quantity and do your statistical test to determine whether it is significant (the usual AB Test). In RCT, afaik, we can sort of trust the outcome because of the randomized treatment assignment without having to approximate the counterfactuals.&lt;/p&gt;

&lt;h1 id=&quot;observational-data&quot;&gt;Observational data&lt;/h1&gt;
&lt;p&gt;In the case of most observational data, where the treatment assignment is not random, we can only recover the causal effect by CONDITIONING on all possible confounding variables.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/conditioning-causal.png&quot; style=&quot;display: block;margin-left: auto;margin-right: auto;width: 80%;&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;caption&quot;&gt;
    Figure 4: effects of conditioning on confounding variable, blocking the path (&lt;a href=&quot;https://www.bradyneal.com/slides/2%20-%20Potential%20Outcomes.pdf&quot;&gt;credits&lt;/a&gt;)
&lt;/div&gt;

&lt;p&gt;Essentially, we want the independence between \(T\) and \((Y1, Y0)\) to happen here but we do this via conditioning on the confounding variables. We have:&lt;/p&gt;

\[(Y0,Y1) \perp T | X\]

&lt;p&gt;This condition reduces the causal effect into a probabilisitic quantity. In the above example, if we assume that gender is our confounding variable, conditioning on it would yield:&lt;/p&gt;

&lt;p&gt;\(P(Y1 = 1) = \sum_x P(Y = 1 | T = 1, X=x) P(X=x)\)
, where there is only one \(x\), namely gender&lt;/p&gt;

&lt;p&gt;Now, to further calculate the causal effect in a non-randomized observational data, it is common to approximate the unobserved counterfactuals with a prediction. In the men group above, we can train a model to predict the unobserved counterfactuals to fill the missing data points (so we have treated men n=1450, not treated men n=1450) and then predict the average treatment effect between the two groups. There are many ways to create this approximate causal model and they usually involve a lot of assumption. For more details I highly recommend to also check &lt;a href=&quot;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-notes/MIT6_S897S19_lec14note.pdf&quot;&gt;this MIT lecture notes&lt;/a&gt;. The most important assumption is of no unmeasured confounders, which only holds when we observe all possible variables that influence both treatment decisions and potential outcomes. In reality, one has to consult with a domain expert to make sure that all variables that influence treatments and potential outcomes are observed.&lt;/p&gt;

&lt;h1 id=&quot;application-in-industry&quot;&gt;Application in industry&lt;/h1&gt;
&lt;p&gt;This is something that I am curious about, but unfortunately I haven’t found the opportunity that allowed me to implement causal inference in a work setting. So I can’t speak from experience. 
Here are some examples of causal inference that I know can be beneficial in industry:&lt;/p&gt;

&lt;h4 id=&quot;uplift-modeling&quot;&gt;Uplift modeling&lt;/h4&gt;
&lt;p&gt;It is aimed at quantifying the treatment effect and identifying the characteristics of individuals most likely to benefit from the benefit. With this information, one thing we can do is to better choose individuals for the next cycle. The characteristics identification is essentially a prediction of counterfactuals for a customer in an experiment setting. Afaik, uplift can also be used to generate demand by giving user more targeted coupons or voucher. Uplift modeling can be used together with AB Test (offline) or multi armed bandit (online).&lt;/p&gt;

&lt;h4 id=&quot;causal-dags-for-forecasting&quot;&gt;Causal DAGs for forecasting&lt;/h4&gt;
&lt;p&gt;I do not know much about this since this is probably still a new field. One example that I know of is from Lyft (check this &lt;a href=&quot;https://www.youtube.com/watch?v=5wbLy4SDuo4&amp;amp;ab_channel=TheTWIMLAIPodcastwithSamCharrington&quot;&gt;talk&lt;/a&gt; from Sean Taylor). At Lyft, they create a causal DAGs with prior experimental evidence to model the causal effect of things. In the causal DAGs, there are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;pure parent nodes that they control (price level, how much we spend on driver incentives)&lt;/li&gt;
  &lt;li&gt;outcome nodes that they monitor (marketplace outcome, things that happen)&lt;/li&gt;
  &lt;li&gt;pure parent nodes that they do not control (how many people request driver organically)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They seem to have another model (like policy variables) that produces plan. This plan is then inserted into the structural causal model to sort of simulate what would happen in the outcome nodes.&lt;/p&gt;

&lt;p&gt;Sean mentioned that in the business context, they need to estimate the effects of choices they make, and making those choices are causes in both the causality and causal inference senses. The estimates produced by their causal models are inputs to decision problems. Ultimately, they still need to do some decision-making (either by humans or algorithmically) that is informed by their models. I think that they cover more complex interventions involving multiple treatments and outcomes.&lt;/p&gt;

&lt;p&gt;If you know any other implementation of causal inference in industry, please do let me know!&lt;/p&gt;

&lt;h1 id=&quot;recap-and-closing&quot;&gt;Recap and closing&lt;/h1&gt;
&lt;p&gt;What this post covered:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Correlation vs causation in a formal way.&lt;/li&gt;
  &lt;li&gt;Counterfactuals as a causal language to capture causal effect correctly. By introducing potential outcomes \((Y1, Y0)\) we see where the failure is.&lt;/li&gt;
  &lt;li&gt;RCT and conditioning on confounding variables as a way to reliably calculate causal effect in an experiment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What this post doesn’t cover:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;List of assumptions that need to hold for the counterfactuals to work.&lt;/li&gt;
  &lt;li&gt;Structural causal model (Pearl): another causal language to describe and capture causal effect.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks for reading this post! I am a noob in causal inference so please do inform me if there is an error or mistake on twitter &lt;a href=&quot;https://twitter.com/rezkaaufar&quot;&gt;@rezkaaufar&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">“Correlation does not imply causation”</summary></entry><entry><title type="html">Tesla in CVPR 2021</title><link href="https://rezkaaufar.github.io/blog/2021/cvpr-2021-tesla/" rel="alternate" type="text/html" title="Tesla in CVPR 2021" /><published>2021-07-06T00:00:00+07:00</published><updated>2021-07-06T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/cvpr-2021-tesla</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/cvpr-2021-tesla/">&lt;p&gt;Akhir juni 2021, Andrej Karpathy selaku director of AI nya tesla melakukan sebuah presentasi mengenai gimana cara self-driving cars bekerja di Tesla. Nah di post kali ini mau gue bahas kesimpulan gue abis nonton video tersebut. Postingan ini ditulis menggunakan Bahasa Indonesia + Bahasa Inggris yang tidak baku.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;pake-kamera-doang&quot;&gt;Pake kamera doang&lt;/h1&gt;

&lt;p&gt;Sebelumnya, self-driving car menggunakan LIDAR untuk pre-mapping situasi jalanan ke format point cloud yang diubah lagi ke HD maps. Konsekuensi menggunakan cara ini adalah mereka mesti rekam dulu situasi jalanan pake lidar terus disimpen. Jadinya manual harus ada orang yang nyetir mobil dengan LIDAR muter-muterin jalan untuk dapetin HD mapsnya. Nah nanti pas testing si self-driving car tinggal lokalisasi situasi jalanan dan navigasi dari HD map yang udah ada untuk melakukan prediksi dia mau ngapain. Nah sekarang, Tesla mau mulai untuk pakai vision-based sensor aja. Jadi mereka langsung bikin map dari kamera pada waktu itu juga. Artinya, si mobil ini ga perlu dikasih HD maps sebelum dia turun kejalan. Semua kondisi jalanan langsung diprediksi saat si mobil jalan sendiri. Menggunakan 8 kamera, si mobil on the spot memprediksi ini jalan nyambungnya kemana, dimana ada lampu merah, zebra cross, pejalan kaki, pesepeda, gedung, dll. Ini bagian menurut gue keren banget. Neural network memang super powerful untuk perception problem.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/tesla-cars.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Ilustrasi kamera+radar sensor+lidar yang digunakan oleh Tesla&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Sebelumnya juga Tesla menggunakan sensor radar untuk membantu prediksi navigasi self-driving car mereka. Fungsi sensor radar ini adalah memberikan mobil informasi mengenai informasi depth-velocity-acceleration. Depth adalah informasi mengenai seberapa jauh objek yang sekarang ada di sekitar mobil, velocity adalah kecepatan dari objek lain yang ada di sekitar mobil, sedangkan acceleration adalah informasi mengenai percepatan dari objek lain yang ada di sekitar mobil. Jadi ya informasi ini penting banget biar si mobil tau objek di sekeliling dia ada apa aja dan gimana cara navigasi yang aman.&lt;/p&gt;

&lt;p&gt;Berikut adalah beberapa masalah dari menggunakan radar:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Secara acak (random) sensor radar memberikan angka yang gak akurat.&lt;/li&gt;
  &lt;li&gt;Masalah saat perlambatan dadakan. Ada banyak kasus menggunakan sensor radar, mobil pas ngerem jadinya kasar tidak santai.&lt;/li&gt;
  &lt;li&gt;Masalah sensor radar bingung gak tau mana stationary object yang benar. Tiba-tiba ngerem pas ada jembatan, tiba-tiba ngerem pas ada mobil parkir dipinggir jalan.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Berdasarkan masalah diatas, mereka akhirnya fokus full invest di sensor kamera aja. Terus gimana dong dapetin informasi depth-velocity-acceleration diatas? Tesla pake neural network buat prediksi depth-velocity-acceleration. Jadi sensor radar diganti sama kamera yang dipersenjatai dengan neural network.&lt;/p&gt;

&lt;h1 id=&quot;kualitas-data&quot;&gt;Kualitas data&lt;/h1&gt;

&lt;p&gt;Kunci dari neural network yang bagus performanya? Ini kata mereka:&lt;/p&gt;
&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/tesla-data.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Kunci suksesnya neural network&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Untuk dapetin data yang bagus gimana caranya? Mereka pake iterative labelling buat dapetin dataset depth-velocity-acceleration yang bagus.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Cara pertama mereka cara yang cuma ngerecord data aja yang banyak dalam bentuk video, jadi mereka bisa dapetin benefit of hindsight yang tidak bisa mereka dapatkan di prediction time. Contoh misal kalo lagi nyetir, didepan ada mobil terus ngeluarin debu-debu. Si neural network bisa jadi udah gak ngeliat mobil didepannya. Kalo kita tambahin data video yang dilabelin secara konsisten, si NN bisa tau oh ini mah debu doang tapi didepan gue masih ada mobil. Dengan kata lain: record -&amp;gt; figure out what happened -&amp;gt; label frame -&amp;gt; use this for prediction.&lt;/li&gt;
  &lt;li&gt;Untuk kasus edge cases mereka bikin triggers. Trigger adalah hand programmed rule yang nentuin oke case mana nih yang mesti gue benerin labelnya. Deploy seed neural network, deploy in shadow mode, make prediction, Terus bikin trigger untuk dapetin case2 yang ada inaccuracies buat nanti dibenerin scr otomatis maupun manual.
Total data yang terkumpul ada 1.5 petabytes. seberapa besar itu neural networknya? :)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/tesla-iterative.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Iterative labeling nya Tesla&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;arsitektur-neural-network&quot;&gt;Arsitektur neural network&lt;/h1&gt;

&lt;p&gt;Mereka pake backbone net kayak resnet abis itu ada beberapa head yang process informasi dari backbone untuk output kayak direction, kinematics, dll. Karena di self-driving cars banyak task yang diprediksi, sepertinya beberapa head itu digroup untuk task yang mirip: misal satu head buat prediksi pixel level classification kayak depth, satu head buat prediksi object level, satu head buat classification satu image, etc. Karpathy juga bilang banyak bagian branch dan head nya yang pake transformers, convolutions, dan juga recurrent neural network.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/tesla-nn.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Neural network nya Tesla&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;ml-ops&quot;&gt;ML Ops&lt;/h1&gt;

&lt;p&gt;Mungkin ini bagian yang paling menarik. Dengan neural network yang super besar dan data yang banyak, gimana mereka handle tech stack nya mereka? Mereka pake in-house supercomputer dan semuanya mereka handle end-to-end. Ngerjain semua stack end-to-end ngasih mereka keuntungan dimana mereka bisa iterasi cepet. Jadi semuanya terintegrasi secara vertikal, dari mulai chip, gpu dan npu, filesystem sendiri, proses buat ngitung gradient secara terdistribusi, semua lah. Mereka investasi gila-gilaan di ML OPS. 5760 gpu nodes dan 1.6tbs filesystem. Ada npu (neural processing unit) jg dan processing chip bikin sendiri.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/tesla-sc.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Supercomputer nya Tesla&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/tesla-npu.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Neural processing unit nya Tesla, lebih terspesialisasi untuk komputasi neural network&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Terima kasih sudah membaca!&lt;/p&gt;

&lt;p&gt;P.S. gambarnya gue crop dari youtube karena gue males jadi ya jelek lah gambarnya intinya gitu.&lt;/p&gt;</content><author><name></name></author><summary type="html">Akhir juni 2021, Andrej Karpathy selaku director of AI nya tesla melakukan sebuah presentasi mengenai gimana cara self-driving cars bekerja di Tesla. Nah di post kali ini mau gue bahas kesimpulan gue abis nonton video tersebut. Postingan ini ditulis menggunakan Bahasa Indonesia + Bahasa Inggris yang tidak baku.</summary></entry><entry><title type="html">a post with diagrams</title><link href="https://rezkaaufar.github.io/blog/2021/diagrams/" rel="alternate" type="text/html" title="a post with diagrams" /><published>2021-07-05T00:39:00+07:00</published><updated>2021-07-05T00:39:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/diagrams</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/diagrams/">&lt;p&gt;This theme supports generating various diagrams from a text description using &lt;a href=&quot;https://github.com/zhustec/jekyll-diagrams&quot; target=&quot;\_blank&quot;&gt;jekyll-diagrams&lt;/a&gt; plugin.
Below, we generate a few examples of such diagrams using languages such as &lt;a href=&quot;https://mermaid-js.github.io/mermaid/&quot; target=&quot;\_blank&quot;&gt;mermaid&lt;/a&gt;, &lt;a href=&quot;https://plantuml.com/&quot; target=&quot;\_blank&quot;&gt;plantuml&lt;/a&gt;, &lt;a href=&quot;https://vega.github.io/vega-lite/&quot; target=&quot;\_blank&quot;&gt;vega-lite&lt;/a&gt;, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; different diagram-generation packages require external dependencies to be installed on your machine.
Also, be mindful of that because of diagram generation the fist time you build your Jekyll website after adding new diagrams will be SLOW.
For any other details, please refer to &lt;a href=&quot;https://github.com/zhustec/jekyll-diagrams&quot; target=&quot;\_blank&quot;&gt;jekyll-diagrams&lt;/a&gt; README.&lt;/p&gt;

&lt;h2 id=&quot;mermaid&quot;&gt;Mermaid&lt;/h2&gt;

&lt;p&gt;Install mermaid using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;node.js&lt;/code&gt; package manager &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm&lt;/code&gt; by running the following command:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt; mermaid.cli
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The diagram below was generated by the following code:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
    John--&amp;gt;&amp;gt;Alice: Great!
{% endmermaid %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;jekyll-diagrams diagrams mermaid&quot;&gt;
  Command Not Found: mmdc
&lt;/div&gt;</content><author><name></name></author><summary type="html">This theme supports generating various diagrams from a text description using jekyll-diagrams plugin. Below, we generate a few examples of such diagrams using languages such as mermaid, plantuml, vega-lite, etc.</summary></entry><entry><title type="html">A primer on decision tree</title><link href="https://rezkaaufar.github.io/blog/2021/decision-tree-a-primer/" rel="alternate" type="text/html" title="A primer on decision tree" /><published>2021-06-18T00:00:00+07:00</published><updated>2021-06-18T00:00:00+07:00</updated><id>https://rezkaaufar.github.io/blog/2021/decision-tree-a-primer</id><content type="html" xml:base="https://rezkaaufar.github.io/blog/2021/decision-tree-a-primer/">&lt;p&gt;Decision tree is the crux of many popular algorithms in data science: xgboost, lightgbm, catboost, etc. In this post I aim to explain how decision tree works in both classification and regression setting. This post is meant as a learning notes also for myself.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;classification-decision-trees&quot;&gt;Classification decision trees&lt;/h1&gt;
&lt;p&gt;Given series of features \(X\) and a categorical label \(Y\), decision tree works by finding which feature in our instances to split and further divide the instances so that we have a leaf that represent the final prediction. For classification trees, we usually do the split based on a technique called gini impurity (the most popular technique). In practice there are several ways to calculate the split for a leaf. Deciding a split based on gini impurity involves several steps:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Calculate gini impurity for a leaf&lt;/li&gt;
  &lt;li&gt;Calculate total gini impurity for a split&lt;/li&gt;
  &lt;li&gt;Decide the split based on feature that has the lowest total gini impurity.&lt;/li&gt;
  &lt;li&gt;Repeat step 1-3 until convergence / stopping criteria&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/classif-toy-dataset.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 1: A toy dataset that is used to illustrate the classification section.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;gini-impurity-for-a-leaf&quot;&gt;Gini impurity for a leaf&lt;/h2&gt;

&lt;p&gt;Gini impurity for a leaf is calculated as:&lt;/p&gt;

\[1 - (\sum_{c=1}^C p_{c}^2)\]

&lt;p&gt;where \(p_{c}\) is the class probability and \(C\) is the total number of class. For binary classification, the equation would become:&lt;/p&gt;

\[1 - y_{1}^2 - y_{0}^2\]

&lt;p&gt;where \(y_1\) is the yes class probability and \(y_0\) is the no class probability.&lt;/p&gt;

&lt;p&gt;For example, if we split the dataset on the “loves sugar” column, we would have:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/loves-sugar.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 2: A split example on the “loves sugar” column.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;where the gini impurity for the left leaf is given by:&lt;/p&gt;

\[1 - (\frac{1}{1+3})^2 - (\frac{3}{1+3})^2 = 0.375\]

&lt;p&gt;and the right gini impurity:&lt;/p&gt;

\[1 - (\frac{2}{2+1})^2 - (\frac{1}{2+1})^2 = 0.444\]

&lt;h2 id=&quot;total-gini-impurity-for-a-split&quot;&gt;Total gini impurity for a split&lt;/h2&gt;

&lt;p&gt;Once we have the gini impurity for each leaf, we need to calculate the gini impurity for a split. Note that these two are different quantities. The gini impurity for a split is the quantity that we use to decide which feature we want to split our instance first. To assess the total gini impurity for a split, we do a weighted average of gini impurities for each leaves:&lt;/p&gt;

\[(\frac{4}{4+3}) 0.375 - (\frac{3}{4+3}) 0.444\]

&lt;p&gt;The idea behind gini impurity is that the more homogeneous sample that we can divide based on a split, then the more pure the split is, hence the lower gini impurity score (0 being the most pure).&lt;/p&gt;

&lt;h2 id=&quot;gini-impurity-for-multi-categorical-variable-and-numeric-continuous-variables&quot;&gt;Gini impurity for multi categorical variable and numeric continuous variables&lt;/h2&gt;
&lt;p&gt;For categorical variable with category greater than 2, we calculate gini impurity for every possible split. For example, if we have a categorical variable with value 1,2, and 3, we split:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;based on 1 and not 1 (2 and 3)&lt;/li&gt;
  &lt;li&gt;based on 2 and not 2 (1 and 3)&lt;/li&gt;
  &lt;li&gt;based on 3 and not 3 (1 and 2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and then we follow the exact same steps as above. The idea is to binarize the split so that we can calculate the leaf gini impurity and split total gini impurity. The same thing also applies to continuous variable. Coming back to our example, “age” column is a numeric continuous variable. To make a split on that variable, we do something like this:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/gini-impurity.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 3: Gini impurity for continuous variables.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Note that we do this on a sorted column because we want the split to be on the sorted instances. The idea is that we decide a split criteria for the continuous variable and we do the exact same steps as the above: treating the split as a binary choice. In the above case, the split criteria is computed based on the mean of every adjacent instances. After we get the mean we then split the instances and calculate the gini impurity like in Figure 2. In practice, there are many ways to decide the split criteria.&lt;/p&gt;

&lt;h2 id=&quot;choosing-the-split&quot;&gt;Choosing the split&lt;/h2&gt;
&lt;p&gt;Based on the example above, we have multiple split criterias and their gini impurity scores. We choose the split that has the lowest gini impurity and made it our first split.&lt;/p&gt;

&lt;h2 id=&quot;adding-branches&quot;&gt;Adding branches&lt;/h2&gt;
&lt;p&gt;We do the same thing as above but now we only consider samples that are included in the node. As we split more, the instances that end up in the leaf will be smaller and smaller.&lt;/p&gt;

&lt;h2 id=&quot;deciding-when-to-stop-adding-leaves&quot;&gt;Deciding when to stop (adding leaves)&lt;/h2&gt;
&lt;p&gt;We stop when we consider a leaf contains only homogeneous instances. We do not need to split more if all instances on a leaf already belong to one label.  We can also stop based on some stopping criteria, for example, by maximum depth. Know when to stop is related to overfitting issue. Splitting perfectly on a training set lead to overfitting whereas splitting fewer lead to underfitting.
If by stopping criteria we end up with impure leaf (3 yes label and 1 no label) then we take the majority as the decision.&lt;/p&gt;

&lt;h2 id=&quot;do-classification-decision-trees-have-probabilities&quot;&gt;Do classification decision trees have probabilities?&lt;/h2&gt;
&lt;p&gt;It is easy to fall into thinking that a classifier always have a probability interpretation. But decision tree is a non-parametric model. It does not have a probabilistic interpretation. One might get a pseudo-probability based on an &lt;a href=&quot;https://rpmcruz.github.io/machine%20learning/2018/02/09/probabilities-trees.html&quot;&gt;impure node&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;regression-decision-trees&quot;&gt;Regression decision trees&lt;/h1&gt;
&lt;p&gt;For regression trees, the leaf produces a continuous value, which is usually an average \(y\) over the splitted samples. Therefore, to evaluate the split, the sum of squared residuals (SSR) of every splitted samples are usually used. These are the steps:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Calculate the average predicted value of a leaf&lt;/li&gt;
  &lt;li&gt;Calculate sum of squared residuals (average predicted value - sample value) of every samples in both sides of the split&lt;/li&gt;
  &lt;li&gt;Decide the split based on a feature that has the lowest sum of squared residuals&lt;/li&gt;
  &lt;li&gt;Repeat step 1 -3 until convergence / stopping criteria&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/regression-toy-dataset.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 1: A toy dataset to illustrate this regression section.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;deciding-the-values-to-split-our-featurecolumn&quot;&gt;Deciding the values to split our feature/column&lt;/h2&gt;
&lt;p&gt;In regression trees, we do this by sorting the column of our features and then we take the average of the adjacent value. This average value will be our threshold to split our feature into two groups. After the split, we calculate the average predicted value of the leaf.&lt;/p&gt;

&lt;h2 id=&quot;sum-of-squared-residuals&quot;&gt;Sum of squared residuals&lt;/h2&gt;
&lt;p&gt;After we get the average predicted value of the leaf, we then calculate the sum of squared residuals, which is given by:&lt;/p&gt;

\[\sum_i (y - f(x_{i}))^2\]

&lt;p&gt;where \(y\) is our label and \(f(x_{i})\) is our prediction value. Here the prediction depends on the average predicted value of the leaf/ where the sample ends up after being splitted.&lt;/p&gt;

&lt;p&gt;Refer to the two figures below for an example of how to do calculate sum of squared residuals for a split:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/ssr-1.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 2a: Example of splitting at a threshold value.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Figure 2a shows how we can calculate a sum of squared residuals for one threshold split, which is at 100 mg. We do this for all possible threshold value for this column:&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/ssr-2.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 2b: Another example of splitting at a threshold value.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;choosing-the-root-for-both-single-variable-and-multiple-variables&quot;&gt;Choosing the root for both single variable and multiple variables&lt;/h2&gt;
&lt;p&gt;If we have multiple variables, we do the same as above for every variable possible and we choose the split that has the lowest sum of squared residuals. If we have a binary column, we are just doing one split. Remember that the idea of a split is that we split the instances into two groups and then we move further from there.&lt;/p&gt;

&lt;div class=&quot;row mt-3&quot;&gt;
    &lt;div class=&quot;col-sm mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/ssr-all.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Figure 3: Illustration to get the smallest SSR in multiple variables. The values are all made up.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;adding-branches-1&quot;&gt;Adding branches&lt;/h2&gt;
&lt;p&gt;We do the same thing as in the classification decision tree. Further split only consider samples that are included in the node. As we split more, the instances that end up in the leaf will be smaller and smaller.&lt;/p&gt;

&lt;h2 id=&quot;deciding-when-to-stop-adding-leaves-1&quot;&gt;Deciding when to stop (adding leaves)&lt;/h2&gt;
&lt;p&gt;There are multiple ways to do this. The most common one is that we stop when there are less than \(k\) instances in the leaf. \(k\) is usually set at 20. We can also stop based on some stopping criteria, for example, by maximum depth. Know when to stop is related to overfitting issue. Splitting perfectly on a training set lead to overfitting whereas splitting fewer lead to underfitting.
With stopping criteria we then take the average \(y\) values of every instances in the leaf and use that as our prediction.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;closing&quot;&gt;Closing&lt;/h1&gt;

&lt;p&gt;Decision tree is a non-parametric model that powers several most popular models in data science. In practice, there are many ways to decide which features to split. This post highlights one of the most popular technique for splitting: gini impurity for classification and sum of squared residuals for regression.&lt;/p&gt;</content><author><name></name></author><summary type="html">Decision tree is the crux of many popular algorithms in data science: xgboost, lightgbm, catboost, etc. In this post I aim to explain how decision tree works in both classification and regression setting. This post is meant as a learning notes also for myself.</summary></entry></feed>