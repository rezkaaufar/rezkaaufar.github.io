<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Core components of recommender systems | Rezka Leonandya</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Core components of recommender systems" />
<meta name="author" content="Rezka Leonandya" />
<meta property="og:locale" content="en" />
<meta name="description" content="The way that recsys is usually taught by starting from its taxonomy (collaborative filtering, content based, hybrid based) is confusing to me at first. In this post I am going to take another path to explain recsys by discussing the core components first and then draw the connection to the recsys taxonomy. Essentially, the majority of recsys objective is to map items and users on the same vector space through a learning objectives so that we can determine items to give to users for a recommendation or which items to show in a similar items page. My post is mostly based on this wonderful talk by James Kirk from Spotify so I highly recommend you to watch the video to gain further understanding." />
<meta property="og:description" content="The way that recsys is usually taught by starting from its taxonomy (collaborative filtering, content based, hybrid based) is confusing to me at first. In this post I am going to take another path to explain recsys by discussing the core components first and then draw the connection to the recsys taxonomy. Essentially, the majority of recsys objective is to map items and users on the same vector space through a learning objectives so that we can determine items to give to users for a recommendation or which items to show in a similar items page. My post is mostly based on this wonderful talk by James Kirk from Spotify so I highly recommend you to watch the video to gain further understanding." />
<link rel="canonical" href="https://rezkaaufar.github.io/recsys-core-components/" />
<meta property="og:url" content="https://rezkaaufar.github.io/recsys-core-components/" />
<meta property="og:site_name" content="Rezka Leonandya" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-08T00:00:00+07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Core components of recommender systems" />
<meta name="twitter:site" content="@rezkaaufar" />
<meta name="twitter:creator" content="@Rezka Leonandya" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Rezka Leonandya"},"dateModified":"2021-05-08T00:00:00+07:00","datePublished":"2021-05-08T00:00:00+07:00","description":"The way that recsys is usually taught by starting from its taxonomy (collaborative filtering, content based, hybrid based) is confusing to me at first. In this post I am going to take another path to explain recsys by discussing the core components first and then draw the connection to the recsys taxonomy. Essentially, the majority of recsys objective is to map items and users on the same vector space through a learning objectives so that we can determine items to give to users for a recommendation or which items to show in a similar items page. My post is mostly based on this wonderful talk by James Kirk from Spotify so I highly recommend you to watch the video to gain further understanding.","headline":"Core components of recommender systems","mainEntityOfPage":{"@type":"WebPage","@id":"https://rezkaaufar.github.io/recsys-core-components/"},"url":"https://rezkaaufar.github.io/recsys-core-components/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="icon" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 64 64'%3E%3Ctext x='50%25' y='50%25' text-anchor='middle' dominant-baseline='central' font-size='52'%3Eüß†%3C/text%3E%3C/svg%3E">
  <style>body {
    max-width: 80ch;
    padding: 3em 1em;
    margin: auto;
    line-height: 1.6;
    font-size: 1.08em;
    font-family: Helvetica, Arial, sans-serif;
}

a {
    color: inherit;
}

a:hover {
    text-decoration: none;
}

img {
    max-width: 100%;
    height: auto;
}

pre {
    overflow: auto;
    background: #f7f7f7;
    padding: 0.75rem;
    border-radius: 6px;
    border: 1px solid #e5e5e5;
}

code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
    background: #f7f7f7;
    padding: 0.1rem 0.35rem;
    border-radius: 4px;
}

blockquote {
    border-left: 3px solid #ddd;
    padding-left: 0.8rem;
    color: #444;
    margin: 1rem 0;
}

header.site-header {
    margin-bottom: 1.5rem;
}

nav ul {
    list-style: none;
    padding: 0;
    margin: 0.4rem 0 0;
    display: flex;
    flex-wrap: wrap;
    gap: 0.6rem 1rem;
}

nav a {
    text-decoration: none;
    border-bottom: 1px solid transparent;
}

nav a.active,
nav a:hover {
    border-color: #111;
}

section { margin: 1.8rem 0; }

.meta { color: #555; font-size: 0.95rem; }

.listing { width: 100%; border-collapse: collapse; }

.listing td { padding: 0.2rem 0.15rem; vertical-align: baseline; }

.listing tr + tr td { border-top: 1px solid #eee; }

.listing .date { white-space: nowrap; padding-right: 0.8rem; color: #666; font-size: 0.95rem; }

.tag {
    display: inline-block;
    padding: 0.1rem 0.55rem;
    border: 1px solid #ddd;
    border-radius: 999px;
    font-size: 0.85rem;
    margin-right: 0.35rem;
    color: #444;
}

footer { margin-top: 2.5rem; padding-top: 1.5rem; border-top: 1px solid #eee; color: #555; font-size: 0.95rem; }

.footer-links {
    display: flex;
    flex-wrap: wrap;
    gap: 0.35rem 0.75rem;
    align-items: center;
    padding: 0;
    margin: 0.5rem 0 0;
    list-style: none;
}

.footer-links a {
    text-decoration: none;
    border-bottom: 1px solid transparent;
}

.footer-links a:hover {
    border-color: #111;
}

.icon {
    font-family: "Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol",sans-serif;
    margin-right: 0.25rem;
}

.social-links {
    display: flex;
    flex-wrap: wrap;
    gap: 0.4rem 0.8rem;
    padding: 0;
    margin: 0.5rem 0 0;
    list-style: none;
}

.social-links a {
    text-decoration: none;
    border-bottom: 1px solid transparent;
}

.social-links a:hover {
    border-color: #111;
}

@media (max-width: 640px) {
    body { font-size: 1em; }
}
</style>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1K5SB4G23C"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-1K5SB4G23C');
  </script>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }
    };
  </script>
  <script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>
  <main>
    <a href="/" aria-label="Home">‚Üê Home</a>
<h1>Core components of recommender systems</h1>
<p class="meta">
  May  8, 2021
  
</p>

<p>The way that recsys is usually taught by starting from its taxonomy (collaborative filtering, content based, hybrid based) is confusing to me at first. In this post I am going to take another path to explain recsys by discussing the core components first and then draw the connection to the recsys taxonomy. Essentially, the majority of recsys objective is to map items and users on the same vector space through a learning objectives so that we can determine items to give to users for a recommendation or which items to show in a similar items page. My post is mostly based on this wonderful talk by <a href="https://www.youtube.com/watch?v=xBMGr08fowA&amp;list=PLmBU_sNMJOn195aabwivQpeOP7IaFjm0o&amp;index=5&amp;t=2593s&amp;ab_channel=mitrecorp" target="_blank" rel="noopener noreferrer">James Kirk from Spotify</a> so I highly recommend you to watch the video to gain further understanding.</p>

<p>Main components of a recommendation system:</p>

<ol>
<li>Interactions Matrix</li>
<li>User and Item Features</li>
<li>User and Item Representation Function</li>
<li>Learning Objective</li>
<li>Prediction Function</li>
</ol>

<p>Let‚Äôs go through it one by one!</p>

<hr />

<h2 id="interaction-matrix">Interaction Matrix</h2>
<p>Interaction Matrix is the main components of a recsys, usually of $M \times N$ size, where $M$ is the number of users and $N$ is the number of items. Note that user-item definition in a recsys is not restrictive to an actual user or item. The user is the receiving and acting entity on the recommendation, whereas the item is the passive entity that is being recommended to the user.</p>

<p>The matrix contains the interaction value between a user and an item. The interaction value can be:</p>

<ul>
<li>positive (likes, 5-star review, purchases, views, etc) or negative (downvotes, 1-star review, skips, etc).</li>
<li>binary or continuous, depending on the data and the problem.</li>
<li>explicit or implicit. explicit interactions are usually an exact number given by the user (upvotes/downvotes, ratings, etd). implicit interactions are actions that are suggested but not stated clearly (views, clicks, counts, etc)</li>
</ul>

<p><img src="/assets/img/interaction-matrix.png" alt="Image" />
<em>Source: <a href="https://www.youtube.com/watch?v=xBMGr08fowA&amp;list=PLmBU_sNMJOn195aabwivQpeOP7IaFjm0o&amp;index=5&amp;t=2593s&amp;ab_channel=mitrecorp" target="_blank" rel="noopener noreferrer">James Kirk‚Äôs slides</a></em></p>

<p>Interaction value should reflect what is the intended effect that we want to happen in our recommender system. For example, if we want users to purchase more given our recommender system, then we want our interaction value to be related to purchase. If we want users to engage more in our platform, then our interaction value should be related to engagement.</p>

<p>We might also want to handle and preprocess our interaction matrix before using it. In some settings, users can give negative explicit interaction. Negative interactions can be a rich signals for the recsys to learn from but we need to be careful in handling them. Some loss functions such as learning-to-rank cannot accomodate negative signals. Interaction matrix is also usually sparse, so we need to handle missing value. In explicit interactions, we can‚Äôt just replace them with zeroes as it indicates that the user do not like the item. Hence we just go about modelling with sparse data. In implicit interactions, it is much safer to replace with zeroes as it indicates no action from the user (no views, no plays, etc).  Missing values are usually what we want to predict with our recsys: giving item recommendation to a particular user that hasn‚Äôt been interacted by the user.</p>

<hr />

<h2 id="useritem-features">User/Item Features</h2>
<p>There are two types of features in a recsys:</p>

<ul>
<li>Indicator features: which represents user and item individually. The feature is unique to every user/item and encoded as one-hot vector. Since indicator is unique to every user/item, this feature does not scale to a lot of users. Indicator feature alone also cannot be used to solve cold-start problem (new users who does not have any interaction data).</li>
<li>Metadata features: any information that we know about user/item that can be incorporated to the recsys. Examples: age, gender, number of child, location, word embeddings, image representation, etc. In some cases, it might be beneficial to preprocess metadata features before using it in our recsys model. For example: converting any string/categorical metadata feature to a numerical type.</li>
</ul>

<p>In a lot of libraries out there, if we do not specify any metadata features for item and user and use interaction matrix solely in our recsys, then by default only the indicator feature is used. The model is only going to learn representation that is unique for every user/item.</p>

<p><img src="/assets/img/user-item-features.png" alt="Image" />
<em>Source: <a href="https://www.youtube.com/watch?v=xBMGr08fowA&amp;list=PLmBU_sNMJOn195aabwivQpeOP7IaFjm0o&amp;index=5&amp;t=2593s&amp;ab_channel=mitrecorp" target="_blank" rel="noopener noreferrer">James Kirk‚Äôs slides</a></em></p>

<ul>
<li>Pure collaborative filtering is an approach where a recsys uses only indicator features.</li>
<li>Pure content-based filtering is an approach where a recsys uses only metadata features for the item and only indicator features for the user. Pure content-based does not share metadata features among users.</li>
<li>When both indicator and metadata features are used they‚Äôre known as a hybrid recsys.</li>
</ul>

<hr />

<h2 id="useritem-representation-function">User/Item Representation Function</h2>
<p>In recsys we want to find a good representation for the user and item. A representation is typically a low-dimensional vector that encodes information regarding the user and item. Getting the representation involves transforming the user/item features via a representation function. Some examples of representation function:</p>

<ol>
<li>Linear Kernels</li>
<li>Neural Networks (Fully Connected, Transformers, Word2vec, Autoencoder)</li>
<li>Passthrough (None)</li>
</ol>

<p>Depending on the design, there are many ways to choose our representation function. Linear kernels are effective with both indicator and metadata features. Linear kernels are also a natural choice for matrix factorization problem. If we have an unstructured data, e.g., text/image that we want to utilize, we can use separate architecture like word2vec or autoencoder to get the text/image representation and then feed it into our recsys representation function. We can also use different representation function for different features, for example, linear kernels for indicator and metadata and passthrough for text/image (directly using representation output from the word2vec or autoencoder).</p>

<hr />

<h2 id="prediction-function">Prediction Function</h2>
<p>A function that outputs the estimated items‚Äô relevance to a particular user. This function converts user/item representation into a prediction. The prediction itself can vary depending on the design: it can be a score that tells us how relevant an item to a user but it can also be a relevance rank on several items for a particular user. Some examples of prediction function:</p>

<ol>
<li>Dot product</li>
<li>Cosine similarity</li>
<li>Euclidian distance</li>
<li>Neural network</li>
</ol>

<hr />

<h2 id="learning-objective">Learning Objective</h2>
<p>This is essentially our loss function that let us uncover the best representation for the user/item. The learning objective converts both the user/item representation and prediction into a loss to learn the best parameter for the recsys model. Learning objective can have a huge impact on the output of the recommendation system. Changes in learning objective can dramatically affect how our recsys feel to the user. Examples of loss function characteristics:</p>

<ul>
<li>Some loss functions learn to approximate the interaction value of a user-item and some loss functions learn to uprank positive interaction and downrank negative interactions for a particular user. The former predicts the interaction value and the latter predicts the ranking of items (learning-to-rank).</li>
<li>Some loss function accomodate negative interactions.</li>
<li>Some loss function are sensitive to interaction magnitude.</li>
<li>Some loss function only account for pairs with interactions (sparse), some loss can be made to compare every interaction pairs (dense), and some loss can learn by comparing pairs with interactions by sampling (sampled).</li>
</ul>

<p>Due to these differences in nature, we must choose learning objective that best fit our goal. Some examples of loss function:</p>

<ol>
<li>Root-mean-square error</li>
<li>KL Divergence</li>
<li>Alternating least square</li>
<li>Bayesian personalized ranking (learning-to-rank)</li>
<li>Weighted approximately ranked pairwise (learning-to-rank)</li>
</ol>

<hr />

<h1 id="combining-it-all-together">Combining it all together</h1>

<p><img src="/assets/img/recsys-build.png" alt="Image" />
<em>Common architecture of a recommender system. Source: <a href="https://www.youtube.com/watch?v=xBMGr08fowA&amp;list=PLmBU_sNMJOn195aabwivQpeOP7IaFjm0o&amp;index=5&amp;t=2593s&amp;ab_channel=mitrecorp" target="_blank" rel="noopener noreferrer">James Kirk‚Äôs slides</a></em></p>

<p>There we have it: the architecture of recommender systems. Let‚Äôs try to design a recommender system based on some cases:</p>

<p>For you page. The example case is to recommend item on a homepage personalized for every user:</p>

<ul>
<li>Interaction matrix: user-item (binary or continuous)</li>
<li>User features: indicator, metadata</li>
<li>Item features: indicator, metadata</li>
<li>User representation: linear</li>
<li>Item representation: linear</li>
<li>Learning objective: RMSE, binary cross entropy, WARP, BPE</li>
<li>Prediction function: dot product, cosine similarity</li>
</ul>

<p>Similar items. The example case is to recommend item given another item:</p>

<ul>
<li>Interaction matrix: item-item (binary or continuous)</li>
<li>User features: indicator, metadata</li>
<li>Item features: same as user features</li>
<li>User representation: linear</li>
<li>Item representation: linear</li>
<li>Learning objective: RMSE, binary cross entropy, WARP, BPE</li>
<li>Prediction function: dot product, cosine similarity</li>
</ul>

<p>With this architecture, we can also incorporate more complex feature representation into the system. For example, if we want to utilize the social graph between user-user, then we can introduce graph neural network that takes an input of user graph (user features) and outputs the representation to be further processed (user representation).</p>

<p><a href="https://arxiv.org/pdf/1902.07243.pdf" target="_blank" rel="noopener noreferrer">For you page</a> utilizing social graph structure:</p>

<ul>
<li>Interaction matrix: user-item (binary or continuous)</li>
<li>User features: user-user graph</li>
<li>Item features: indicator, metadata, etc</li>
<li>User representation: graph neural network</li>
<li>Item representation: linear</li>
<li>Learning objective: custom RMSE</li>
<li>Prediction function: feed forward neural network</li>
</ul>

<p>Simpler recsys such as user-based and item-based that does not require training also fits in this architecture. Let‚Äôs take a look:</p>

<p>User-based recsys:</p>

<ul>
  <li>Interaction matrix: user-item</li>
  <li>User Features: Indicator but we use the row in the interaction matrix</li>
  <li>Item Features: -</li>
  <li>User representation: -</li>
  <li>Item representation: -</li>
  <li>Learning objective: -</li>
  <li>Prediction function: dot product, cosine similarity. to predict the rating of an item $y$ that user $x$ hasn‚Äôt seen, we query top $k$ users that are similar to user $x$ (have rated item $y$) and calculate the weighted average of the ratings.</li>
</ul>

<p>Item-based recsys:</p>

<ul>
  <li>Interaction matrix: user-item</li>
  <li>User Features: -</li>
  <li>Item Features: Indicator but we use the column in the interaction matrix</li>
  <li>User representation: -</li>
  <li>Item representation: -</li>
  <li>Learning objective: -</li>
  <li>Prediction function: dot product, cosine similarity. to predict the rating of an item $y$ that user $x$ hasn‚Äôt seen, we query top $k$ users that are similar to item $y$ ($y$ has been rated by user $x$) and calculate the weighted average of the ratings.</li>
</ul>

<h2 id="is-there-a-recsys-model-that-does-not-fit-into-this-architecture">Is there a recsys model that does not fit into this architecture?</h2>

<p>Yes! In some cases we can use the interaction matrix to design the training data and not use it as our label. You can find some of the examples <a href="https://eugeneyan.com/writing/recommender-systems-graph-and-nlp-pytorch/" target="_blank" rel="noopener noreferrer">here</a> where the author tries to create a pseudo-sentences of products to then be fed into a word2vec training. This setting does not use the interaction matrix as the label.</p>

<p>Thanks for reading! Contact me on twitter if you spot any mistake.</p>



  </main>

  <footer>
    <div class="footer-top">
      <div>¬© <span id="copyright-year">2026</span> Rezka Leonandya.</div>
      <div class="meta">Built with Jekyll + Featherweight-inspired minimal styling.</div>
    </div>
    <div class="meta"><span id="page-size"></span> ¬∑ <span id="load-time"></span></div>
  </footer>
  <script>
    (function() {
      const sizeEl = document.getElementById('page-size');
      const timeEl = document.getElementById('load-time');
      const yearEl = document.getElementById('copyright-year');
      const update = () => {
        if (sizeEl) sizeEl.textContent = `Size: ${document.documentElement.outerHTML.length} bytes`;
        if (timeEl) timeEl.textContent = `Load time: ${Math.round(performance.now())} ms`;
        if (yearEl) yearEl.textContent = new Date().getFullYear();
      };
      if (document.readyState === 'complete') {
        update();
      } else {
        window.addEventListener('load', update, { once: true });
      }
    })();
  </script>
</body>
</html>
