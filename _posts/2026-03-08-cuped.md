---
layout: post
title: Things to look out for when running CUPED
description: CUPED is a great method to reduce variance in an AB test. However, there are some things to look out for when running CUPED.
date: '2026-03-08'
tags: [statistics, experimentation]
published: false
---

We have a new feature that we want to test. We calculate sample sizes required and boom the stakeholders are not happy with the duration it took to run the test. We go back to the drawing board and try to find a way to reduce the sample size. Can we reduce the sample size required but still maintain the same power?

One of the most common method to reduce variance in an AB test is by using CUPED (Controlled-experiment Using CUPED). CUPED is a variance reduction technique that can be used to reduce the variance of an estimator by using a control variate. 

In this post, we are not going to go through the math behind CUPED. Instead, we are going to go through the things to look out for when running CUPED. We'll start with a brief introduction on what CUPED is and how it works. And then we go into the considerations that we need to take into account when running CUPED.

# CUPED background

The idea of CUPED is that we can use historical data to neutralize pre-existing noise. Let's say we have a metric that we measure $Y_1$ that we observe after we start the experiment. The goal is to find a historical pre-experiment data $Y_0$ that has a strong correlation with $Y_1$ to adjust the observed $Y_1$. In practice, $Y_0$ needs to be:

- as correlated as possible with $Y_1$ to maximize the variance reduction
- independent of the treatment assignment. 

In the original CUPED [paper](https://dl.acm.org/doi/abs/10.1145/2433396.2433413), the authors suggest to use the pre-treatment outcome $Y_0$. In other words, the unit of $Y_0$ has to be the same as $Y_1$. 

To illustrate, lets say our analysis unit is a user. We want to measure the users' conversions $Y_1$ by giving a discount voucher $T$ as our treatment. We can use the users' conversions $Y_0$ before the experiment starts as our control variate. 

What we do is:
- Regress $Y_1$ on $Y_0$ and estimate the coefficient $\hat{\theta}$.
- Compute $Y_{1}^{cuped} = Y_1 - \hat{\theta} Y_0$ for each unit.
- Compute the difference of $Y_{1}^{cuped}$ between treatment and control group.

Here is how it looks in python code:

```python
theta = smf.ols('conversion_post ~ conversion_pre', data=df).fit().params[1]

df['conversion_cuped'] = df['conversion_post'] - theta * (df['conversion_pre'] - np.mean(df['conversion_pre']))

smf.ols('conversion_cuped ~ discount_voucher', data=df).fit().summary().tables[1]
```

What we will observe is that the output of the second regression will have a much smaller standard error compared to the first regression. This is because CUPED has reduced the variance of the estimator. For more illustrative example, you can refer to [this notebook](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/cuped.ipynb).

# Do we even observe $Y_1$ before the experiment starts?

The first thing that you might be wondering is that do we even observe $Y_1$ before the experiment starts? The answer is no. We only observe $Y_1$ after the experiment starts. So then how do we do the regression before the experiment to get the smaller standard deviation? Remember that when calculating sample size, you need to get the variance of the estimator. So we need to estimate the variance of the estimator before the experiment starts. 

# My analysis unit lacks consistent pre-experiment identity

# 





